[{"title":"离开那座岛后--谨以此文纪念消逝的2023","url":"/2024/01/21/%E7%A6%BB%E5%BC%80%E9%82%A3%E5%BA%A7%E5%B2%9B%E5%90%8E-%E8%B0%A8%E4%BB%A5%E6%AD%A4%E6%96%87%E7%BA%AA%E5%BF%B5%E6%B6%88%E9%80%9D%E7%9A%842023/","content":"岛间碎笔\n沉睡在实验室的我们，把三分之一的生命平铺在格子间里。当工位变成离体的心脏，伴随我们一起爱，一起生活，直到鞠躬尽瘁，死而后已。\n\n我的学校在小谷围岛上，几代南汉帝王的陵冢也在这座岛上。\n年初的日子里，大部分时间是在实验室度过的。每个人寄生在自己不大的工位上，靠着椅子义务接受屏幕散发的热辐射。\n\n有时候感觉自己的确很疲惫，累了就很喜欢胡思乱想，思来想去，始终琢磨不出是因为什么干起了这行。\n工作的目的其实是为了更好的生活，很多时候现实不得不把你推向另一个极端，慢慢的也逐渐失去了热爱。人必生活着，爱才有所附丽。偶尔为了冲淡苦涩，就想出去走走。于是在一个随意的周末，和朋友混进了隔壁广美的美术馆里。\n美术馆特别气派，首先迎接我们的是一个由路障僵尸帽子做成的大榴莲。里面还有不少抽象的展厅，这些东西也总是能让工科学生眼前一亮。\n\n实验室的朋友们偶尔也会一起出去团建，在岛上一个干净的草坪上搭起帐篷吃烤肉。\n这也是大学生活里唯一体验过的一次户外烧烤。我们平日团建活动不多，所以这种经历弥足珍贵。\n广州的夏天特别热，记得去年十一月的某几天夜里，宿舍耗能三级的空调还在呼呼的吹。\n\n宿舍楼下随处可见哈基米，无辜的眼神能把心都给融掉。\n不过这些学长们也干了不少坏事，一旦习惯了被投喂，饿了就会去偷我们的外卖。\n记得有次帮同学带饭，去操场刷圈时，把饭盒放到了操场一边，跑完步发现饭丢了。气不过直接联系了学校保卫处，最后发现打包盒其实是被学校的狗叼走了。\n\n脆弱平庸\n在那段活得侥幸而茫然的日子里，每晚抬头都能看到实验室上空的月亮，低头却又瞥见聒噪的代码和歹毒的字符串铸成的凶器。\n\n上半年坚持得最久的一件事，算是参加开源了。\n有时候真的会觉得自己很疲惫。除了要完成实验室堆积如山的开发任务，还要打磨始终不让自己满意的提案和代码。不管是申请谷歌编程之夏(GSoC)，还是后面的中科院开源之夏(OSPP)，都花了好久的时间去写提案和代码。\n由于是第一次申请开源活动，总担心落选，每次精神内耗的时候就打开提案反复去折腾。最后的结果也确实没让自己失望，参加的两个社区都提交了代码。\n\n\n其实自己也常常觉得，把事情看得太过沉重。但每想到将来还是模糊的，都会无数次阵痛。阵痛过后，便想去重建快要坍塌的精神内核。也许大学四年过后回头看看，不后悔，便是给自己最好的答复。\n在OSPP结束不久后，正巧杭州开始举办云栖大会了，室友恰巧也要到云栖大会上作为嘉宾演讲，我也就沾他的光和他一起过去了。\n\n云栖大会就在云栖小镇上面，整个会场挺大，有很多展馆和展台。\n这次到杭州除了打卡到几个具有纪念意义的展台外，还见到了开源社区的导师以及其他参与社区的同学。之前一直是网上和导师们交流，所以见到面还挺激动的。\n\n\n来云栖大会，当然少不了薅社区的纪念品了。有些奖品只需要排队就能拿，比如英伟达旁就有很长的队伍在排队抽奖；有的奖品需要一定门槛，得答题才能领。一天下来，还真能刷到不少礼品。\n\n人工墙\n人生就像一个喝得摇摇欲坠的封建王朝。\n\n今年九月份，很意外地拿到了小红书的offer。没想太多，背上包、拉上行李箱，在火车上睡了一晚就到上海了。\n其实我已经很久没有坐过绿皮火车了，现在出行更多的是高铁，几个小时就能到目的地。只有在很小的时候才会和父母坐绿皮火车旅行，那时候还没有高铁，虽然开得很慢，但总感觉只有这样才能叫旅行。人总是会在某些时间段里是孤独的，一个人到上海，就好像两年前一个人到广州求学一样。很多时候你总希望有熟悉的人在陪伴在你身边，但你转身过后，故人已经愈来愈远了。\n\n我其实是很乐于去不同的地方实习的，虽然租房可能会让你存不下来钱，但至少可以体验不同城市生活。趁年轻，多去走走。红薯作为人生实习的第一站，充满了各种的期待，不知道自己会遇到哪些人，会遇到哪些事。来上海的第一件事，就是到公司附近瞧瞧，初到上海的那天，由于还没正式入职录入人脸信息，因此暂时进不了公司，随手拍下了见到红薯的第一张照片。\n\n入职第一天中午，Mentor 就带我去楼下的烧烤店吃烤肉，一顿饭下来也算体会到了上海的物价，两个人在一个烤肉店吃饱，竟然花了将近四百块。\n\n小红书里常常可以见到来扫楼的明星，在实习的那段时间里，卡卡、Alan Walker、新海诚都来过。而且扫楼是在公司内部，所以安保并没有想象中严格。\n\n小组里就我一个开发实习生，刚入职的那段时间，一个人在工位上很拘束。每天除了工作，就没其他活动了。下班后，呆在狭小的出租屋里，没有人说话。一次恰好感冒了，残存最后一点模模糊糊的意识，到网上买了药，送来一看还买错药了。后面没过几天又开始牙疼，这才知道长了两颗智齿，晚上疼得翻来覆去睡不着觉。有时候常常感觉，一个人守在一座城市真的很难熬。写字楼吞下一个完整的你，吐出一个疲惫的身体，濒死的瞳孔向上看去，等着最后一点余晖落下。\n\n与我对接的产品同事人特别好，回家后都和他有聊不完的话题。\n他带我去吃火锅、去酒吧。我对自己能进酒吧也感觉挺意外的，算是一次尝试吧。酒是分酸甜苦辣的，他为我挑了杯甜酒，一直喝到凌晨三点，那晚坐在回家的出租车上，倒头就睡着了。\n\n时间一点点过去了，还是等到了离开小红书这一天。\n临走之前，和小组所有同学留下一张大合影，拍了好些“毕业照”，第二天就离开上海去北京了。直到现在，依然会想起几个月前，一个人拖着行李来上海的那天。这一次，过期的梦里，没有甜酒。\n朝碧海而暮苍梧从小到大，很喜欢一个人出去旅游。默数今年到过的地方，发现倒也不少。\n年初的时候，我从广州，跑到了南宁和北海，暑假又陪父母去了趟江西，往北到了安徽黄山，最后到了重庆。之后因为在上海实习，趁周末环沪游到了杭州和无锡。\n在杭州短途旅行的时候，抽空去了一趟浙江音乐学院，感触挺深的。在浙音，无论是操场，还是人行小道都不见什么人影。他们大部分都呆在琴房和表演厅了。\n\n练琴室整栋楼的大门是能随便进出的，但是每个格子间都有密码锁。每间琴房里都有一架钢琴，但是房间的功能却又不局限于练钢琴，这里也有练古筝亦或声乐的同学，整体布局和琴行里的琴房没什么出入。所以，也隐隐约约看到平行时空里另一种选择的自己，如果十年前没有放弃，精神状态同现在会有什么区别。\n\n另外不得不提的一件事，就是上海的万圣节之夜。那天晚上，很多人化了妆并且 cos 成各种角色。\n那时我就在想，在我家那边是从不可能用这大架势过万圣节的。如果出现一大群 Cosplayer 在万圣节的晚上堵在大街上，并且人人都为这个节日而欢呼，我的第一反应一定是我还没醒过来。这也是上海这座城市留给我的第一印象：巨大包容性和创造力。\n不过这场活动也引起了很多媒体的讨论，褒贬不一。但我的观点比较佛系：不赞美、不责难，只求了解认识而已。\n万圣节当天的很多商店，也都被cos了一番，比如长着章鱼触须的餐厅、门口悬挂帽子的咖啡厅。\n\n2023在烟花的亮光和鞭炮的爆炸声中消逝殆尽，旧的故事也就写到这里，而我还得裹挟着平凡继续走下去。新的一年，祝大家平安顺遂、年轻快乐。\n"},{"title":"OSPP-2023 ｜ Flexible Raft 杂谈","url":"/2023/11/13/OSPP-2023-%EF%BD%9C-Flexible-Raft-%E6%9D%82%E8%B0%88/","content":"\n前言\n在 OSPP-2023 官方选题中，我最终中选了 SOFA Stack 社区中 【结合 NWR 实现 Flexible Raft】这一选题，最近也收到成功结项的消息。关于 Flexible Raft，其实我们最早可以追溯到 Heidi Howard 博士于2016年发布的一篇论文《改进分布式共识》，Howard 是剑桥大学计算机科学与技术系系统研究小组的分布式系统研究员，这篇论文一经发出，受到广泛关注。截至目前，网络上还并没有找到该篇论文的中文翻译，于是我自己把这件事情给做了，详见：Flexible Paxos：重新审视法定人数交集-论文中译。中译版最初是通过机译之后，再对不太准确的地方进行手工校验修正，在格式和文字风格上最大程度维持了原样，若仍有不准确的地方读者可以留言斧正。该篇论文基于 paxos 算法，提出了一个比 paxos 更 Flexible 的共识协议改进，能够更加灵活的去调整协商和共识效率。而本篇文章将基于 FPaxos 的核心思想进而过渡到 Flexible Raft 的实现思路。\n\n\n分布式一致性分布式系统通常由异步网络连接的多个节点构成，每个节点有独立的计算和存储。通常来说，分布式一致性一般指的是数据的一致性。比如分布式存储系统，通常以多副本冗余的方式实现数据的可靠存储。同一份数据的多个副本必须保证一致，而数据的多个副本又存储在不同的节点中，这里的分布式一致性问题就是存储在不同节点中的数据副本的取值必须一致。分布式系统最朴实的目标是把一堆普通机器的计算&#x2F;存储等能力整合到一起，然后整体上能够像一台超级机器一样对外提供可扩展的读写服务。如果不保证一致性，那么就说明这个系统中的数据根本不可信，数据也就没有意义，那么这个系统也就没有任何价值可言。在分布式系统中，各个节点之间需要进行通信来保持数据的一致性，而通信的实现方式有共享内存和消息传递两种模型。基于消息传递通信模型的分布式系统，不可避免的会发生下面的错误：机器宕机，进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复。那么在这种复杂的情况下该如何保证一致性呢？这时就需要交给我们的 Paxos&#x2F;Raft 算法去实现了。Paxos&#x2F;Raft 算法能够快速正确的在一个分布式系统中对某个数据的值达成一致，并且保证无论发生任何异常，都不会破坏整个系统的一致性。\nPaxos 旧约在遥远的古希腊，有一座小岛，它位于爱奥尼亚海的东面。当时的人们在岛上进行民主决策实践。我们的主人公 Lamport 早先年考古希腊群岛，就被这座小岛所吸引，可能是从这个背景中获得了灵感，于是，他将小岛的名字 Paxos 用于命名自己提出的共识协议，以表示分布式系统中的协商和共识过程，这就是Paxos 名称的由来。\nBasic Paxos 算法过程Propser 有两个重要属性，提案编号 N, 提案 V, 简记 Proposer(N, V)。Acceptor 有三个重要属性，响应提案编号 ResN, 接受的提案编号 AcceptN, 接收的提案 AcceptV， 简记Acceptor（ResN, AcceptN, AcceptV）。\n第一阶段: Prepare准备阶段Proposer：Proposer 生成全局唯一且递增的提案编号N，向所有Acceptor发送Prepare请求，这里无需携带提案内容，只携带提案编号即可, 即发送 Proposer(N, null)。Acceptor：Acceptor 收到 Prepare 请求后，有两种情况：\n\n如果 Acceptor 首次接收 Prepare 请求, 设置 ResN&#x3D;N，同时响应ok\n如果 Acceptor 不是首次接收 Prepare 请求，则：\n\n\n若请求过来的提案编号 N小于等于上次持久化的提案编号 ResN，则不响应或者响应 error。\n若请求过来的提案编号 N大于上次持久化的提案编号 ResN, 则更新 ResN &#x3D; N，同时给出响应。响应的结果有两种，如果这个 Acceptor 此前没有接受过提案， 只返回 ok。否则如果这个 Acceptor 此前接收过提案，则返回 ok 和上次接受的提案编号 AcceptN，接收的提案 AcceptV。\n\n第二阶段: Accept接受阶段Proposer： Proposer 收到响应后，有两种情况：\n\n如果收到了超过半数响应 ok , 检查响应中是否有提案，如果有的话，取提案 V&#x3D; 响应中最大 AcceptN 对应的 AcceptV，如果没有的话，V则有当前 Proposer 自己设定。最后发出 accept 请求，这个请求中携带提案 V。\n如果没有收到超过半数响应 ok , 则重新生成提案编号 N，重新回到第一阶段，发起 Prepare 请求。\n\nAcceptor： Acceptor 收到 accept 请求后，分为两种情况：\n\n如果发送的提案请求 N 大于此前保存的 RespN，接受提案，设置 AcceptN &#x3D; N, AcceptV &#x3D; V, 并且回复 ok。\n如果发送的提案请求 N 小于等于此前保存的 RespN，不接受，不回复或者回复 error。\n\nProposer： Proposer 收到 ok 超过半数，则 V 被选定，否则重新发起 Prepare 请求。\n第三阶段: Learn学习阶段Learner： Proposer 收到多数 Acceptor 的 Accept 后，决议形成，将形成的决议发送给所有 Learner。\nFlexible Paxos\n关于作者下面是微软剑桥实验室对Heidi Howard的介绍：\n\n我是微软剑桥研究院机密计算小组的高级研究员。我的研究处于分布式计算理论和实践的交叉点，重点是开发弹性和值得信赖的分布式计算机系统。此前，我是剑桥大学三一大厅的计算机科学研究员VMware Research的附属&#x2F;访问研究员和剑桥大学计算机科学与技术系的附属讲师。我于2019年因对分布式共识的研究获得了剑桥大学的博士学位。我最出名的可能是我在Paxos算法方面的工作，特别是 Flexible Paxos 的发明。\n\n\n为什么要拥抱FPaxos我们想象这样一个场景：假设 paxos 集群中成员总数是 n，prepare 阶段参与的成员数是 Q1，accept 阶段参与的成员数是Q2，那么 Basic Paxos 正确性保障最本质的诉求是 Q1 与 Q2 两个阶段要有重合成员，以确保信息可以传递。当前一个普遍的实现机制是：只要 Q1 与 Q2 两个阶段都有多数派（majority）成员参与即可。可是，我们发现只要保证 prepare 与accept 两个阶段参与的成员数超过成员总数，即 Q1 + Q2 &gt; N，那一样能够满足 Q1 与 Q2 两个阶段要有重合成员的要求，如果是这样，那我们选择的参数就非常灵活了。\n\n那么，动态调节 Q1 和 Q2 的意义在哪里？我们知道 prepare 阶段事实上可以看作 Leader 选举，accept 阶段则可以看成日志同步，即涉及 IO 操作。我们是否可以考虑把Q1调大，而Q2调小，来减小 IO 操作带来的压力；又或者我们不再局限于多数派模型，动态设置更灵活的两阶段成员数量，来更好的支持异地容灾呢？\n\n我们来举一个具体的例子来更好的理解 Flexible Paxos 的优势。现在有一个 n&#x3D;5 的集群节点，按照以往的 majority 模式，我们 prepare 和 accept 阶段需要的成员数都是3。如果我们设置FPaxos 「n&#x3D;5，prepare&#x3D;4，accept&#x3D;2」，此时的IO依赖于两个节点存活响应，那么我们是不是IO的压力就小了，日志同步这种慢操作所依赖的节点更少了。另外一个比较经典的例子，AWS曾经提出了可用区（Availability+Zone）的概念，在每个区域 （Region）都有多个可用区。AZ之间物理隔离，独立供电，一个AZ故障，不会影响另外一个AZ，但AZ之间是连通，且网络耗时低。简单可以将AZ理解为独立机房或逻辑机房，这样可以利用AZ的隔离性，对业务进行跨AZ部署，实现高可用。在这样的异地容灾背景下，如果使用多数派模型，像 [2,2,2] 这样的 3 AZ 场景，无论是 prepare 阶段还是 accept 阶段，他最多只能接受挂掉一个 zone，因为 6 节点的多数派是 4。那其实 [2,2,2] 相较于 [2,2,1] 是没有增加额外的容灾能力的，后者也最多只允许宕掉一个 zone。但是如果我们引入了 Flexible Paxos 就不一样了。如果我们将 [2,2,2] 的 Q1 设置为 4，Q2 设置为 3，这样我们能抗住挂掉一个 AZ，这时还剩下 4 个节点，即使宕掉的 AZ 中有 Leader，仍然可以重新选举出一个新的 Leader，并且在accept 阶段还可以另外支持宕掉一个节点，毕竟Q2&#x3D;3。\nFlexible Raft有人说过这样一句话：在 Paxos 算法找到一个开源的“杀手级”工业应用之前，Raft 算法的赶超速度几乎是不可阻挡的。Paxos 协议族会逐步成为 Raft 算法的优化策略（所以我们看到这次SOFA-JRaft 在 OSPP-2023 开源之夏给出的选题，结合 NWR Quorum 模型实现 Flexible Raft 这个课题，说明 Raft 算法已经开始拥抱 Flexible Raft 这个灵活派的新特性了）。对于 Raft 算法来说，其实要像 Flexible Paxos 算法一样实现 Flexible Raft 也是大同小异的。Paxos 的 prepare 阶段类似于 Raft 的 Leader 选举，Paxos 的 Accept 阶段类似于 Raft 的日志复制。那么我们如何在兼容多数派模型的情况下，同时引入 Flexible 模型呢？社区给出的答案是：我们可以结合 Quorum NWR 模型来实现这一设计，具体思考可以参考 SOFA-JRaft 的讨论。举个例子，在一个总节点数为 5 的集群中，多数派模型的NWR结构是 [n&#x3D;5，r&#x3D;3，w&#x3D;3]；而 Flexible Raft 的 NWR 可以设计为 [n&#x3D;5，r&#x3D;2，w&#x3D;4] 或者 [n&#x3D;5，r&#x3D;4，w&#x3D;2]，甚至可以 [n&#x3D;5，r&#x3D;5，w&#x3D;1]，只需要满足 r+w &#x3D; n+1 就好了。所以接下来，我会给出在本次 OSPP-2023 开源之夏活动中，对于 Flexible Raft 的设计与具体实现。\n使用规则Flexible Raft 的功能使用方法很简单，这里以 jraft-example 模块下我提供给社区的 Flexible Raft 功能测试用例模块为例子：FlexibleRaftServer 中，我们只需要使用 nodeOptions.enableFlexibleRaft(true) 打开 Flexible Raft 开关，然后调用 nodeOptions.setFactor(6, 4) 对读写 factor 因子进行设置，这样就能够启动 Flexible Raft了。\npublic FlexibleRaftServer(final String dataPath, final String groupId, final PeerId serverId,                          final NodeOptions nodeOptions) throws IOException &#123;    // init raft data path, it contains log,meta,snapshot    FileUtils.forceMkdir(new File(dataPath));    // here use same RPC server for raft and business. It also can be seperated generally    final RpcServer rpcServer = RaftRpcServerFactory.createRaftRpcServer(serverId.getEndpoint());    // GrpcServer need init marshaller    FlexibleGrpcHelper.initGRpc();    FlexibleGrpcHelper.setRpcServer(rpcServer);    // register business processor    FlexibleRaftService flexibleRaftService = new FlexibleRaftServiceImpl(this);    rpcServer.registerProcessor(new FlexibleGetValueRequestProcessor(flexibleRaftService));    rpcServer.registerProcessor(new FlexibleIncrementAndGetRequestProcessor(flexibleRaftService));    // init state machine    this.fsm = new FlexibleStateMachine();    // set fsm to nodeOptions    nodeOptions.setFsm(this.fsm);    // set storage path (log,meta,snapshot)    // log, must    nodeOptions.setLogUri(dataPath + File.separator + &quot;log&quot;);    // meta, must    nodeOptions.setRaftMetaUri(dataPath + File.separator + &quot;raft_meta&quot;);    // snapshot, optional, generally recommended    nodeOptions.setSnapshotUri(dataPath + File.separator + &quot;snapshot&quot;);    // enable flexible raft    nodeOptions.enableFlexibleRaft(true);    // set flexible raft factor    nodeOptions.setFactor(6, 4);    // init raft group service framework    this.raftGroupService = new RaftGroupService(groupId, serverId, nodeOptions, rpcServer);    // start raft node    this.node = this.raftGroupService.start();&#125;\n\n我们对 Majority Raft 模式的使用进行了兼容，如果需要使用 Majority Raft，可以使用下面代码给出的方式设置开启 FlexibleRaft 为 false，或者更简单的方法不进行任何对FlexibleRaft 参数的操作，因为 Jraft 默认是使用 Majority Raft 的。\nnodeOptions.enableFlexibleRaft(false);\n\n\n设计思路\nNWR 模型我们知道，NWR 是一种在分布式存储系统中用于控制一致性级别的策略。N 在分布式存储系统中，代表有多少份备份数据 。W 代表一次成功的更新操作要求至少有 W 份数据写入成功。R 代表一次成功的读数据操作要求至少有 R 份数据成功读取。满足 W + R &gt; N 的情况下，读 Quorum 和写 Quorum 一定存在交集，这个相交的成员一定拥有最新的数据，那么这个分布式系统一定是满足强一致性的。例如，在一个 N&#x3D;3 的 Raft 集群中，W 是 2、R 是 2 的时候，W+R&gt;N，这种情况对于集群而言就是强一致性的。所以基于以上思路，首先我们要对 Quorum 这一核心类进行设计。Quorum 类结构很简单，只需要{int w，int r} 来表示读写节点数量即可。\npublic class Quorum &#123;    private int w;    private int r;    public Quorum(int w, int r) &#123;        this.w = w;        this.r = r;    &#125;&#125;\n\n\nConfiguration 升级设计好 Quorum 类之后，如何在每个节点运行过程中随时获取或者修改？这时我们需要整合到 Configuration 类中了。在原有的 Configuration 类中，是没有 quorum、readFactor、writeFactor 和 isEnableFlexible 的，因为这几个属性是为了适配 Fleixble Raft 而新添加的元素。\npublic class Configuration implements Iterable&lt;PeerId&gt;, Copiable&lt;Configuration&gt; &#123;    private static final Logger   LOG              = LoggerFactory.getLogger(Configuration.class);    private static final String   LEARNER_POSTFIX  = &quot;/learner&quot;;    private Quorum                quorum;    private Integer               readFactor;    private Integer               writeFactor;    private Boolean               isEnableFlexible = false;    private List&lt;PeerId&gt;          peers            = new ArrayList&lt;&gt;();    // use LinkedHashSet to keep insertion order.    private LinkedHashSet&lt;PeerId&gt; learners         = new LinkedHashSet&lt;&gt;();&#125;\n\n\nQuorum 计算规则我们根据使用规则可以知道，用户端要使用 Flexible Raft 功能需要打开 NodeOptions 中 Flexible Raft 的开关，并且设置好 factor 因子的大小。那么我们又是如何根据 factor 因子计算出一个 raft 集群的w和r是多少呢？为了实现 w 和 r 的计算逻辑，我们提供了一个计算工厂BallotFactory类专门处理NWR的计算规则。\ncheckValid：校验读写factor是否都不为空，并且其和为10calculateWriteQuorum：根据size与writeFactor计算w的大小calculateReadQuorum：根据计算出的w，根据公式 r = n - w + 1 计算calculateMajorityQuorum：计算 Majority 模式下的 w 和 rbuildFlexibleQuorum：如果打开 Flexible 模式，用于计算该模式下的 QuorumbuildMajorityQuorum：如果打开 Majority 模式，用于计算该模式下的 QuorumconvertConfigToLogEntry：将 configuration 转换为 LogEntryconvertOldConfigToLogOuterEntry：将 oldConfiguration 转换为 LogEntry\n\npublic final class BallotFactory &#123;    private static final Logger     LOG                  = LoggerFactory.getLogger(BallotFactory.class);    private static final String     defaultDecimalFactor = &quot;0.1&quot;;    private static final BigDecimal defaultDecimal       = new BigDecimal(defaultDecimalFactor);    public static Quorum buildFlexibleQuorum(Integer readFactor, Integer writeFactor, int size) &#123;        // if size equals 0,config must be empty,so we just return null        if (size == 0) &#123;            return null;        &#125;        // Check if factors are valid        if (!checkValid(readFactor, writeFactor)) &#123;            LOG.error(&quot;Invalid factor, factor&#x27;s range must be (0,10) and the sum of factor should be 10&quot;);            return null;        &#125;        // Partial factor is empty        if (Objects.isNull(writeFactor)) &#123;            writeFactor = 10 - readFactor;        &#125;        if (Objects.isNull(readFactor)) &#123;            readFactor = 10 - writeFactor;        &#125;        // Calculate quorum        int w = calculateWriteQuorum(writeFactor, size);        int r = calculateReadQuorum(readFactor, size);        return new Quorum(w, r);    &#125;    public static Quorum buildMajorityQuorum(int size) &#123;        // if size equals 0,config must be empty,so we just return null        if (size == 0) &#123;            return null;        &#125;        int majorityQuorum = calculateMajorityQuorum(size);        return new Quorum(majorityQuorum, majorityQuorum);    &#125;    private static int calculateWriteQuorum(int writeFactor, int n) &#123;        BigDecimal writeFactorDecimal = defaultDecimal.multiply(new BigDecimal(writeFactor))            .multiply(new BigDecimal(n));        return writeFactorDecimal.setScale(0, RoundingMode.CEILING).intValue();    &#125;    private static int calculateReadQuorum(int readFactor, int n) &#123;        int writeQuorum = calculateWriteQuorum(10 - readFactor, n);        return n - writeQuorum + 1;    &#125;    private static int calculateMajorityQuorum(int n) &#123;        return n / 2 + 1;    &#125;    public static boolean checkValid(Integer readFactor, Integer writeFactor) &#123;        if (Objects.isNull(readFactor) || Objects.isNull(writeFactor)) &#123;            LOG.error(&quot;When turning on flexible mode, Both of readFactor and writeFactor should not be null.&quot;);            return false;        &#125;        if (readFactor + writeFactor == 10 &amp;&amp; readFactor &gt; 0 &amp;&amp; readFactor &lt; 10 &amp;&amp; writeFactor &gt; 0 &amp;&amp; writeFactor &lt; 10) &#123;            return true;        &#125;        LOG.error(&quot;Fail to set quorum_nwr because the sum of read_factor and write_factor is &#123;&#125; , not 10&quot;,            readFactor + writeFactor);        return false;    &#125;    public static LogEntry convertConfigToLogEntry(LogEntry logEntry, Configuration conf) &#123;        if (Objects.isNull(logEntry)) &#123;            logEntry = new LogEntry();        &#125;        logEntry.setEnableFlexible(false);        logEntry.setPeers(conf.listPeers());        final LogOutter.Quorum.Builder quorumBuilder = LogOutter.Quorum.newBuilder();        LogOutter.Quorum quorum = quorumBuilder.setR(conf.getQuorum().getR()).setW(conf.getQuorum().getW()).build();        logEntry.setQuorum(quorum);        return logEntry;    &#125;    public static LogEntry convertOldConfigToLogOuterEntry(LogEntry logEntry, Configuration conf) &#123;        if (Objects.isNull(logEntry)) &#123;            logEntry = new LogEntry();        &#125;        logEntry.setEnableFlexible(false);        logEntry.setOldPeers(conf.listPeers());        final LogOutter.Quorum.Builder quorumBuilder = LogOutter.Quorum.newBuilder();        LogOutter.Quorum quorum = quorumBuilder.setR(conf.getQuorum().getR()).setW(conf.getQuorum().getW()).build();        logEntry.setOldQuorum(quorum);        return logEntry;    &#125;&#125;\n\n\nNode 节点初始化启动节点后，一定会调用 NodeImpl#init 方法来初始化一个节点。在原有初始化init方法的基础上，额外添加下面的 Flexible 逻辑以适配灵活派模型。\n// 省略非 Flexible 模式下的相关代码Configuration initialConf = options.getInitialConf();    \t// 判断开启 Flexible 模式后，校验设置的 factor 是否合规        if (initialConf.isEnableFlexible()            &amp;&amp; !checkFactor(initialConf.getWriteFactor(), initialConf.getReadFactor())) &#123;            return false;        &#125;        this.conf = new ConfigurationEntry();        this.conf.setId(new LogId());        // if have log using conf in log, else using conf in options        if (this.logManager.getLastLogIndex() &gt; 0) &#123;            checkAndSetConfiguration(false);        &#125; else &#123;            this.conf.setConf(this.options.getInitialConf());            // initially set to max(priority of all nodes)            this.targetPriority = getMaxPriorityOfNodes(this.conf.getConf().getPeers());        &#125;        if (!this.conf.isEmpty()) &#123;            Requires.requireTrue(this.conf.isValid(), &quot;Invalid conf: %s&quot;, this.conf);        &#125; else &#123;            LOG.info(&quot;Init node &#123;&#125; with empty conf.&quot;, this.serverId);        &#125;        // 判断开启 Majority Mode 后，设置 Majority Quorum        if (Objects.isNull(conf.getConf().getQuorum()) &amp;&amp; !conf.getConf().isEnableFlexible()) &#123;            Quorum quorum = BallotFactory.buildMajorityQuorum(conf.getConf().size());            conf.getConf().setQuorum(quorum);        &#125;        // 初始化预投票选票Ctx：prevVoteCtx        if (!prevVoteCtx.init(conf.getConf(), conf.getOldConf())) &#123;            LOG.error(&quot;Fail to init prevVoteCtx.&quot;);            return false;        &#125;        // 初始化投票选票Ctx：voteCtx        if (!voteCtx.init(conf.getConf(), conf.getOldConf())) &#123;            LOG.error(&quot;Fail to init voteCtx.&quot;);            return false;        &#125;\n\n\n写操作约束我们根据选择的 Majority&#x2F;Flexible 的计算规则，生成的 WriteQuorum 最终会在初始化 Ballot 的时候赋值到 quorum 属性。Ballot 选票会在上文提到的 preVoteCtx 与 voteCtx 中进行初始化，用于投票计算，当收到任意节点的投票后，quorum 大小减一。\npublic boolean init(final Configuration conf, final Configuration oldConf) &#123;    this.peers.clear();    this.oldPeers.clear();    this.quorum = this.oldQuorum = 0;    int index = 0;    if (conf != null &amp;&amp; !conf.isEmpty()) &#123;        for (final PeerId peer : conf) &#123;            this.peers.add(new UnfoundPeerId(peer, index++, false));        &#125;        // 获取conf中的Quorum.W        quorum = conf.getQuorum().getW();    &#125;    if (oldConf == null) &#123;        return true;    &#125;    index = 0;    for (final PeerId peer : oldConf) &#123;        this.oldPeers.add(new UnfoundPeerId(peer, index++, false));    &#125;    if (!oldConf.isEmpty()) &#123;        this.oldQuorum = oldConf.getQuorum().getW();    &#125;    return true;&#125;\n\n对于投票是否完成并达成共识，可以使用 isGranted 方法去判断。\npublic boolean isGranted() &#123;    return this.quorum &lt;= 0 &amp;&amp; this.oldQuorum &lt;= 0;&#125;\n\n\n读操作约束在 ReadIndexHeartbeatResponseClosure 中定义了心跳响应的属性，如下述代码所示。failPeersThreshold 参数即允许心跳失败的阈值，可以看到使用到了我们提供的quorum.getR() 来获取 Read Quorum。\npublic ReadIndexHeartbeatResponseClosure(final RpcResponseClosure&lt;ReadIndexResponse&gt; closure,                                         final ReadIndexResponse.Builder rb, final Quorum quorum,                                         final int peersCount) &#123;    super();    this.closure = closure;    this.respBuilder = rb;    this.quorum = quorum;    this.failPeersThreshold = peersCount - quorum.getR() + 1;    this.ackSuccess = 0;    this.ackFailures = 0;    this.isDone = false;&#125;\n\n可以看到 ReadIndexHeartbeatResponseClosure 心跳响应回调重写了 run 方法，用来判断读请求的操作是否还满足心跳要求，即当前 leader 是否还是 leader。\n@Overridepublic synchronized void run(final Status status) &#123;    if (this.isDone) &#123;        return;    &#125;    if (status.isOk() &amp;&amp; getResponse().getSuccess()) &#123;        this.ackSuccess++;    &#125; else &#123;        this.ackFailures++;    &#125;    // Include leader self vote yes.    if (this.ackSuccess + 1 &gt;= this.quorum.getR()) &#123;        LOG.info(&quot;Reading successfully...&quot;);        this.respBuilder.setSuccess(true);        this.closure.setResponse(this.respBuilder.build());        this.closure.run(Status.OK());        this.isDone = true;    &#125; else if (this.ackFailures &gt;= this.failPeersThreshold) &#123;        LOG.info(&quot;Reading failed...&quot;);        this.respBuilder.setSuccess(false);        this.closure.setResponse(this.respBuilder.build());        this.closure.run(Status.OK());        this.isDone = true;    &#125;&#125;\n\n\n节点如何宣判死亡在之前的 Majority 模式下，我们判断节点死亡的方式很简单，只需要根据多数派节点数是否存活即可下决定，或者说参考 Read Quorum。但当我们引入了 Flexible 模式，情况就不同了。因为我们希望在写多读少的场景下，如果死亡节点数即使不再满足 Read Quorum 的数量，仍然不能让leader下线，此时系统是可以继续写的。所以我们的判断逻辑就与之前截然不同了，在最少存活节点数的选择上，我们会选择 Read Quorum&#x2F; Write Quorum 的最小值。下面的源码中 targetCount 的计算方式即是兼容两种模式的实现。可能有人会问这会不会影响 Majority 模型呢？答案是不会，因为多数派模式下的 ReadQuorum 和 WriteQuorum 大小是相等的。所以新增的这个判断适配的是灵活排模型。\nprivate boolean checkDeadNodes0(final List&lt;PeerId&gt; peers, final long monotonicNowMs, final boolean checkReplicator,                                final Configuration deadNodes) &#123;    final int leaderLeaseTimeoutMs = this.options.getLeaderLeaseTimeoutMs();    int aliveCount = 0;    long startLease = Long.MAX_VALUE;    for (final PeerId peer : peers) &#123;        if (peer.equals(this.serverId)) &#123;            aliveCount++;            continue;        &#125;        if (checkReplicator) &#123;            checkReplicator(peer);        &#125;        final long lastRpcSendTimestamp = this.replicatorGroup.getLastRpcSendTimestamp(peer);        if (monotonicNowMs - lastRpcSendTimestamp &lt;= leaderLeaseTimeoutMs) &#123;            aliveCount++;            if (startLease &gt; lastRpcSendTimestamp) &#123;                startLease = lastRpcSendTimestamp;            &#125;            continue;        &#125;        if (deadNodes != null) &#123;            deadNodes.addPeer(peer);        &#125;    &#125;    // If the writeFactor in a cluster is less than readFactor and the number of nodes    // is less than r and greater than or equal to w, we hope to still be in a writable state.    // Therefore, read requests may fail at this time, but the cluster is still available    Quorum quorum = this.conf.getConf().getQuorum();    int targetCount = this.conf.getConf().isEnableFlexible() &amp;&amp; quorum.getW() &lt; quorum.getR() ? quorum.getW()        : quorum.getR();    if (aliveCount &gt;= targetCount) &#123;        updateLastLeaderTimestamp(startLease);        return true;    &#125;    return false;&#125;\n\n\n灵活派属性持久化当节点宕机后重启，需要知道下线前节点是 flexible mode 还是 majority mode。设置的 Read Factor 与 Write Factor大小是多少等等一系列参数。所以我们需要对这些参数做一个持久化。在 log.proto 中添加了适配 flexible raft 的新字段：\nmessage Quorum&#123;  optional int32 w = 1;  optional int32 r = 2;&#125;message PBLogEntry &#123;  required EntryType type = 1;  required int64 term = 2;  required int64 index = 3;  repeated bytes peers = 4;  repeated bytes old_peers = 5;  required bytes data = 6;  optional int64 checksum = 7;  repeated bytes learners = 8;  repeated bytes old_learners = 9;  optional int32 read_factor = 10;  optional int32 write_factor = 11;  optional int32 old_read_factor = 12;  optional int32 old_write_factor = 13;  optional bool  is_enable_flexible = 14;  optional Quorum quorum = 15;  optional Quorum old_quorum = 16;&#125;\n\n同理的，在 raft.proto 也需要添加适配灵活派新字段：\nmessage EntryMeta &#123;    required int64 term = 1;    required EntryType type = 2;    repeated string peers = 3;    optional int64 data_len = 4;    // Don&#x27;t change field id of `old_peers&#x27; in the consideration of backward    // compatibility    repeated string old_peers = 5;    // Checksum fot this log entry, since 1.2.6, added by boyan@antfin.com    optional int64 checksum = 6;    repeated string learners = 7;    repeated string old_learners = 8;    optional int32 read_factor = 9;    optional int32 write_factor = 10;    optional int32 old_read_factor = 11;    optional int32 old_write_factor = 12;    optional bool  isEnableFlexible = 13;    optional Quorum quorum = 14;    optional Quorum old_quorum = 15;&#125;;message SnapshotMeta &#123;    required int64 last_included_index = 1;    required int64 last_included_term = 2;    repeated string peers = 3;    repeated string old_peers = 4;    repeated string learners = 5;    repeated string old_learners = 6;    optional int32 read_factor = 7;    optional int32 write_factor = 8;    optional int32 old_read_factor = 9;    optional int32 old_write_factor = 10;    optional bool isEnableFlexible = 11;    optional Quorum quorum = 12;    optional Quorum old_quorum = 13;&#125;\n\nV1&#x2F;V2两个版本的编码解码器(encoder&#x2F;decoder)也需要适配新规则，具体代码此处就不贴了。\n一致性检测我们书写的 Flexible Raft 是否满足线性一致性呢，这需要我们使用 Jepsen 框架去进行校验了。具体的工作我也有形成文档，可以参考我之前这篇博客：JRaft-jepsen 线性一致性测试。最终的检测结果已经以PR的形式提交到Jraft-jepsen仓库，详见：https://github.com/sofastack/sofa-jraft-jepsen/pull/3。\n写在最后感谢中科院软件所”开源软件供应链点亮计划”提供这次宝贵的机会，同时也要感谢刘源远导师和 SOFA-Stack 社区在项目开发期间给予的帮助，在这里推荐一本有关分布式共识算法的书籍：《深入理解分布式共识算法》，希望它也能帮助大家更好的去理解、学习分布式共识算法。\n","tags":["开源之夏"]},{"title":"Flexible Paxos：重新审视法定人数交集-中译","url":"/2023/10/26/FlexiblePaxos%EF%BC%9A%E9%87%8D%E6%96%B0%E5%AE%A1%E8%A7%86%E6%B3%95%E5%AE%9A%E4%BA%BA%E6%95%B0%E4%BA%A4%E9%9B%86%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/","content":"\nHeidi Howard博士论文原作：论文原著-英文版Flexible Paxos 大本营：Flexible Paxos 博客官网Heidi Howard 在 Dockercon 2017上的演讲：使用灵活的Paxos构建可扩展、弹性和一致的系统Heidi Howard 博士于2016年在伦敦 OSCON 的演讲幻灯片：分布式共识：使不可能成为可能-分布式共识领域的关键结果概述由于市面上关于 Flexible Paxos 的文章较少，也没有见到 Flexible Paxos 算法论文的中译版，所以本篇文章打算对论文做一个简单的翻译。若有不准确的地方恳请留言斧正。\n\nFlexible Paxos：重新审视法定人数交集\nAuthor：海蒂·霍华德(1,2) 达丽娅·马尔基(1) 亚历山大·斯皮格曼(1,3)Date：2016 年 8 月 25 日，星期四\n\n剑桥大学计算实验室，英国剑桥，&#104;&#x65;&#x69;&#x64;&#x69;&#x2e;&#x68;&#x6f;&#x77;&#97;&#x72;&#100;&#64;&#99;&#108;&#46;&#x63;&#x61;&#x6d;&#46;&#97;&#x63;&#x2e;&#117;&#x6b;\nVMware Research，美国帕洛阿尔托，&#x64;&#97;&#104;&#108;&#x69;&#97;&#x6d;&#x61;&#x6c;&#107;&#x68;&#x69;&#x40;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#46;&#99;&#111;&#x6d;\n维特比电气工程系，海法理工学院，32000，以色列，&#115;&#x61;&#115;&#x68;&#x61;&#115;&#64;&#x74;&#x78;&#x2e;&#116;&#x65;&#99;&#x68;&#x6e;&#x69;&#111;&#x6e;&#46;&#x61;&#x63;&#x2e;&#105;&#108;\n\n\nAbstract分布式共识是现代分布式系统不可或缺的一部分。 广泛采用的 Paxos 算法使用两个阶段，每个阶段都需要多数同意才能可靠地达成共识。 在本文中，我们证明作为许多生产系统基础的 Paxos 是保守的。 具体来说，我们观察到 Paxos 的每个阶段都可能使用非相交的群体。 多数法定人数不是必需的，因为仅需要跨阶段交叉。利用这种对原始公式中的要求的弱化，我们提出了Flexible Paxos，它概括了Paxos算法以提供灵活的仲裁。 我们证明了Flexible Paxos在现有的分布式系统中是安全、高效且易于使用的。 最后，我们讨论了这一结果的广泛影响。 例如，当接受器数量为偶数时，通过将第二阶段仲裁的大小减少 1 来提高可用性，并利用小的不相交的第二阶段仲裁来加速稳态。\t\t\nIntroduction分布式共识是面对失败时仍能达成一致的问题。 这是现代分布式系统中的一个常见问题，其应用范围从分布式锁定和原子广播到强一致的键值存储和状态机复制[35]。 Lamport 的 Paxos 算法 [18, 19] 就是这个问题的解决方案之一，自其发布以来，它已被广泛应用于教学、研究和实践。Paxos 的核心是使用两个阶段，每个阶段都需要一部分参与者（称为法定人数）同意才能继续。 Paxos的安全性和活跃性是建立在保证任意两个法定人数相交的基础上的。为了满足这一要求，法定人数通常由固定参与者组中的任何多数组成，尽管也提出了其他法定人数方案。在实践中，我们通常希望就一系列值达成一致，称为 Multi-Paxos [19]。 我们使用Paxos的第一阶段建立一个参与者作为领导者，并使用Paxos的第二阶段提出一系列 value。 要承诺某个值，领导者必须始终与至少法定人数的参与者进行沟通，并等待他们接受该值。在本文中，我们弱化了原始协议中所有法定人数相交的要求，仅要求来自不同阶段的法定人数相交。 在 Paxos 的每个阶段中，使用不相交仲裁是安全的，并且多数仲裁不是必需的。 我们将这种新的表述称为Flexible Paxos (FPaxos)，因为它允许开发人员灵活地为两个阶段选择法定人数，前提是他们满足上述要求。 严格来说，FPaxos 比 Paxos 更通用，并且具有相交群体的 FPaxos 相当于 Paxos。鉴于 Multi-Paxos 及其变体的广泛部署，这样的结果具有广泛的实际应用价值。 由于 Paxos 的第二阶段（复制）比第一阶段（领导者选举）更常见，因此我们可以使用 FPaxos 来减少常用的第二阶段仲裁的大小。 例如，在一个 10 个节点的系统中，我们可以安全地只允许 3 个节点参与复制，前提是在从领导者故障中恢复时需要 8 个节点参与。 这种以增加第 1 阶段法定人数为代价减少第 2 阶段法定人数的策略在本文正文中被称为简单法定人数。简单的仲裁系统减少了延迟，因为领导者将不再需要等待大多数参与者接受提案。 同样，它提高了稳态吞吐量，因为不相交的参与者集现在可以接受提案，从而更好地利用参与者并减少网络负载。 我们为此付出的代价是可用性降低，因为系统可以容忍更少的故障，同时从领导者故障中恢复。稍后，我们将令人惊讶地说明，并不总是需要为了稳定状态性能而牺牲可用性。 示例包括当接受器数量为偶数时将第二阶段法定人数的大小减少一，以及利用诸如网格法定人数之类的法定人数系统来减少两个阶段的法定人数大小。在下一节中，我们使用标准术语概述基本 Paxos 算法。 已经熟悉该算法的读者应该直接进入下一节。 在第 3 节中，我们详细描述了观察结果，然后在第 4 节中阐述了为什么这种灵活性在实践中有用。 §5 非正式地描述了为什么削弱 Paxos 对群体交集的假设是安全的。 在第 6 节中，我们评估了 FPaxos 的简单实现并证明了其有用性。 第 7 节概述了如何动态选择法定人数，第 8 节将 FPaxos 与该领域的现有工作联系起来。 附录包括 FPaxos 算法的 TLA+ [20] 规范，该算法已根据我们的安全假设进行了模型检查。\nPaxos我们希望在一组进程之间决定一个值 v。 系统是异步的，每个进程都可能失败，并且它们之间传递的消息可能会丢失。 每个进程都有一个或多个角色。 我们有三个角色：提议者，一个希望选择特定值的过程；接受者，一个同意并坚持决定值的过程；或者学习者，一个希望学习决定值的过程。拥有候选值的提议者将尝试向接受者提议该值。 如果已经选择了一个值，提议者将学习它。 提议值的过程有两个阶段：阶段 1 和阶段 2，每个阶段都需要大多数接受者同意才能继续。 我们现在将详细了解每个阶段：第一阶段 - 准备和承诺i 提议者选择一个唯一的提议编号 p 并向接受者发送prepare(p)。ii 每个接受者接收prepare(p)。 如果 p 是承诺的最高提案编号，则 p 被写入持久存储，并且接受者回复 Promise(p’,v’)。 (p’,v’) 是最后接受的提案（如果存在），其中 p’ 是提案编号，v’ 是相应的提案值。iii 一旦提议者收到大多数接受者的承诺，就会进入第二阶段。 否则，它可能会使用更高的提案编号重试。\n第 2 阶段 - 提议并接受i 提案者现在必须选择一个值 v。如果在第 1 阶段返回了多个提案，则它必须选择与最高提案编号相关的值。 如果没有返回提案，则提案者可以选择自己的 v 值。然后提案者将 suggest(p,v) 发送给接受者。ii 每个接受者收到一个提议(p,v)。 如果p等于或大于最高承诺提案编号，则将承诺提案编号和接受的提案写入持久存储，接受者回复accept(p)。iii 一旦提议者收到大多数接受者的accept(p)，它就知道v值已经决定了。 否则，它可能会使用更高的提案编号再次尝试阶段 1。Paxos 保证一旦决定了一个值，这个决定就是最终的，并且不能选择不同的值。 如果 n 个接受者中的 ⌊n&#x2F;2⌋ + 1 个接受者已启动并能够通信，Paxos 将达成协议。 证明进展需要我们对系统的同步性做出一些假设，因为我们不能保证真正的异步系统的进展[7]。\n图 1：不同系统规模下 LibPaxos3 的性能。 实验设置的详细信息在§6 中给出。通常，我们希望就一系列值达成一致，我们将其称为槽。 我们可以使用不同的 Paxos 实例来决定序列中的每个值，即第 i 个槽由第 i 个 Paxos 实例决定。 然而在实践中，我们可以做得更好，这被称为 Multi-Paxos。Paxos 的第一阶段与为任何给定实例提议的值无关，因此可以在知道要提议的值之前执行第一阶段。 此外，我们可以将第一阶段聚合到一系列槽上。 我们将完成第一阶段的提议者称为领导者。 为了避免失一般性，我们引入另一个代理人，即客户，他是提案价值的起源。 客户端可能位于系统外部，也可能与其他流程（例如提议者）位于同一地点。图 1 说明了 Multi-Paxos 在实践中的执行情况。 x 轴显示系统中副本的数量，每个副本扮演提议者、接受者和学习者的角色。 蓝线表示客户端观察到的提交延迟，红线表示平均请求吞吐量。 正如我们所期望的，增加副本数量将增加延迟并降低吞吐量。 这些发现与之前的研究一致 [29, 26]。法定人数系统是我们选择哪些接受者集合能够形成有效法定人数的方法。 据观察，Paxos 可以推广到用任何保证任意两个仲裁具有非空交集的仲裁系统来取代多数仲裁 [19, 21]。 群体交集的基本定理指出，其弹性与参与者的负载（因此吞吐量）成反比[31]。 因此，对于 Paxos 及其相交的群体，我们只能希望通过降低弹性来增加吞吐量，反之亦然。 在本文的其余部分中，我们表明，通过削弱法定人数交叉要求，我们可以摆脱弹性和性能之间固有的权衡。 \t\t\t\nFPaxos在本节中，我们观察到 Paxos 的通常描述（如第 2 节中给出）比必要的更加保守。 为了解释这一观察结果，我们将区分 Paxos 第一阶段使用的法定人数（我们将其称为 Q1）和第二阶段使用的法定人数（称为 Q2）。Paxos 对 Q1 和 Q2 都使用接受者的多数法定人数。 通过要求法定人数至少包含大多数接受者，我们可以保证任何两个法定人数之间至少有一个共同的接受者。 Paxos 的安全性和进度证明是建立在所有法定人数相交的假设之上的。我们观察到，仅需要第 1 阶段群体 (Q1) 和第 2 阶段群体 (Q2) 相交。 不需要要求 Q1 彼此相交，也不需要 Q2 彼此相交。 我们将其称为灵活 Paxos (FPaxos)，它概括了 Paxos 算法。 如果我们允许任意一组至少 ⌊n&#x2F;2⌋ + 1 个接受者在 FPaxos 中形成 Q1 或 Q2 群体，那么 FPaxos 就相当于 Paxos。利用这一观察，我们可以利用许多非相交的群体系统。 在其最直接的应用中，我们可以简单地减小 Q2 的大小，但代价是增加 Q1 仲裁的大小。正如我们之前讨论的，Paxos 的第二阶段（复制）比 Multi-Paxos 中的第一阶段（领导者选举）更加频繁。 因此，减少 Q2 的大小可以通过减少参与复制所需的接受器数量来减少常见情况下的延迟，提高系统对慢速接受器的容忍度，并允许我们使用不相交的接受器集来获得更高的吞吐量。 我们为此付出的代价是，当我们需要建立新的领导者时，需要更多的接受者参与。 虽然在稳定的系统中选举新的领导者是罕见的事件，但如果发生足够多的故障，我们无法形成 Q1 法定人数，那么在一些接受者恢复之前我们无法取得进展。与 Paxos 一样，只要至少有足够的接受者启动并能够进行通信以形成 Q1 和 Q2 法定人数，系统就能够取得进展。 与 Paxos 不同的是，只要我们能够形成与该阶段相对应的法定人数，我们就能够在给定阶段内取得进展。 更具体地说，如果发生了足够多的故障，使得提议者无法再形成 Q1 法定人数，但能够形成较小的 Q2 法定人数，则系统可以继续安全地取得进展，直到需要新的领导者为止。 如果接受者在当前领导者发生故障之前恢复，那么系统不会因此而遭受可用性损失。\nImplications现在我们将考虑观察到仅在 Paxos 的两个阶段之间需要群体交叉的实际含义。 数据库和数据复制领域已经存在大量关于仲裁系统的文献，现在可以更有效地应用于共识领域。 有趣的示例系统包括加权投票[9]、层次结构[15]和摇摇欲坠的墙[34]。 然而现在，我们将通过考虑三个简单的仲裁系统示例来说明 FPaxos 的实用性：(1)多数仲裁 (2)简单群体 (3)网格群体。\nMajority quorums目前，Paxos 要求当接受器数量 n 为偶数【 Lamport 观察到多数可以扩展到包括 n&#x2F;2 大小的集合的恰好一半 [16] 】时，使用大小为 n&#x2F;2 + 1 的群体。 根据我们的观察，我们可以安全地将 Q2 的大小从 n&#x2F;2+1 减少 1 到 n&#x2F;2，并保持 Q1 不变。 这样的更改实施起来很简单，通过减少参与复制所需的接受器数量，我们可以减少延迟并提高吞吐量。 此外，我们还提高了系统的容错能力。 与 Paxos 一样，如果最多发生 n&#x2F;2 − 1 次失败，那么我们保证能够取得进展。 然而，与 Paxos 不同的是，如果恰好有 n&#x2F;2 个接受者失败并且领导者仍然存在，那么我们就能够继续取得进展并且不会遭受可用性损失。图 2 显示了实践中具有多数法定人数的 FPaxos 的两个示例跟踪。 由于系统由四个接受器组成，FPaxos 对 Q1 使用多数（3 个接受器），但对 Q2 仅需要两个接受器。 在示例中，两个提案者希望提交相互冲突的提案。 在图 2a 中，提议者 1 首先执行 FPaxos 并提交其值 a。 随后，提议者二执行一轮 Paxos 并获悉该值。 在图 2b 中，两个提议者都成功执行了 FPaxos 的第一阶段，并同时向不相交的接受者集提交了冲突的提议值。 两个 Q2 都会与两个 Q1 相交，因此只有其中一个会成功。 不成功的提议者可以使用更高的提议编号重试并学习所选值。。\nSimple quorums我们将使用术语“简单仲裁”来指代仲裁系统，其中任何接受者都能够参与仲裁，并且每个接受者的参与都被平等地计算。 简单法定人数是多数法定人数的直接概括。 Paxos 要求所有法定人数相交，因此，正如我们之前讨论的，每个法定人数必须至少包含严格多数的接受者才能满足此要求。相比之下，FPaxos 仅要求来自不同阶段的群体相交。 因此，具有简单法定人数的 FPaxos 必须要求 |Q1| + |Q2| &gt; N. 我们知道，在实践中，第二阶段比第一阶段更常见，因此我们允许 |Q2| &lt; N&#x2F;2 并相应增加 Q1 的大小。 对于给定的 Q2 大小和接受器数量 N，那么我们第一阶段仲裁的最小大小是 |Q1| &#x3D; N − |Q2| + 1. FPaxos 将始终能够处理最多 |Q2| − 1 次失败。 然而，如果在 |Q2| 之间 至 N − |Q2| 发生故障时，我们可以继续复制，直到需要新的领导者为止。\n图 2：使用改进的多数仲裁的 FPaxos 执行示例。 该系统由四个接受者（A1-A4）和两个提议者（P1，P2）组成图 3：使用 5 x 4 网格形成 20 个接受器系统的法定人数的示例正如之前所观察到的[25]，我们不需要向所有接受者发送准备和提议消息，只需至少向|Q1|发送即可。 或|Q2| 接受者。 如果这些接受者中的任何一个没有回复，那么领导者可以将消息发送给更多的接受者。 这将消息数量从 4 × N 减少到 (2 × |Q1|) + (2 × |Q2|)。 这是以增加延迟为代价的，因为领导者可能不会选择最快的接受者，并且在发生故障时必须重新传输。\nGrid quorums简单群体的关键限制是，减小 Q2 的大小需要相应增加 Q1 的大小才能继续确保交集。 网格仲裁是替代仲裁系统的一个示例。 网格仲裁可以通过在仲裁大小、选择仲裁时的灵活性和容错能力之间提供不同的权衡来减小 Q1 的大小。 网格仲裁方案将 N 个节点排列成 N1 列乘 N2 行的矩阵，其中 N1 × N2 &#x3D; N，仲裁由行和列组成。 与许多其他仲裁系统一样，网格仲裁限制哪些接受器组合可以形成有效的仲裁。 这一限制使我们能够减少法定人数的大小，同时仍然确保它们相交。Paxos 要求所有 quorum 相交，因此一种合适的网格方案需要一行和一列来形成 quorum【实际上，使用一行加上其下方每一行中的一个网格项的任意选择就足够了。 平均仲裁大小将变为 N1 + (1&#x2F;2)N2，尽管最坏的情况仍然是 N1 +N2 −1】。图 3a 显示了使用此方案的 Q1 仲裁和 Q2 仲裁示例。 这会将法定人数的大小从 N 的多数减少到 N1 + N2 − 1。可以容忍的故障数量范围为 MIN(N1,N2)，其中每行或每列中的一个节点失败到 (N1 − 1) × (N2 − 1)，只剩下一行和一列。在 FPaxos 中，我们可以安全地将 Q1 的法定人数减少到大小为 N1 的一行，以及 Q2 的大小为 N2 的一列，示例如图 3b 所示。 这种结构很有趣，因为来自同一阶段的法定人数永远不会相交，在实践中，对于在一组接受器之间均匀分配 FPaxos 的负载可能很有用。 对于简单的仲裁，系统无法从领导者故障中恢复，同时任何一组|Q2| &#x3D; N&#x2F;2 接受者失败。 现在有了网格法定人数，我们不再平等地对待所有失败，重要的是哪些接受者失败了，而不仅仅是有多少接受者失败了。 回想一下，只要我们仍然可以形成该阶段的法定人数，我们就能够在给定阶段取得进展。 例如，让我们考虑一下图 3 中任一网格中的四个接受器是否会失败。 如果这些故障发生在两列中，那么两个系统都会取得进展。 如果所有失败的节点都在一列内，那么 Paxos 将不会取得任何进展，但 FPaxos 将继续，直到需要新的领导者为止。 同样，如果给定行中的所有节点都发生故障，FPaxos 将能够完成 Q1 并因此恢复所有过去的决策，然后它可以安全地退回到重新配置协议以删除或替换失败的接受器并继续取得进展 。 在实践中，故障不是独立的，因此我们可以将接受器分布在机器、机架甚至数据中心之间，以最大限度地减少同时发生故障的可能性。通过思想实验，让我们考虑在使用网格法定人数时设置 N1 &#x3D; 1 和 N2 &#x3D; N 或等效地设置 |Q1| &#x3D; N 和 |Q2| &#x3D; 1，具有简单法定人数。 任何单个接受者都足以形成 Q2，但是每个接受者都必须参与 Q1。 在实践中，这将允许所有接受者在单跳中了解决定的值，但是在每个接受者都启动之前，我们将无法从领导者故障中恢复。或者，让我们考虑在使用网格仲裁时设置 N1 &#x3D; N 和 N2 &#x3D; 1 或等效地设置 |Q1| &#x3D; 1 和 |Q2| &#x3D; N 具有简单法定人数。 这将要求每个接受者都参与 Q2，但 Q1 只需要一个接受者。 如果有任何接受者仍在运行，那么我们可以完成 Q1 并学习过去的决策。 正如之前所观察到的 [25, 23]，这样的结构允许我们仅使用 f + 1 个接受器而不是 2f + 1 个接受器来容忍 f 次失败。\nSafetyLamport 的 Paxos 安全证明并未充分利用所做出的假设，即所有法定人数都会相交。 为了完整起见，在本节中我们概述了 FPaxos 的安全性证明。为了确保 FPaxos 的安全，做出的每个决定都必须是最终决定。 换句话说，一旦决定了一个值，就不能决定不同的值。 这可以正式表达为以下要求：定理 1. 如果值 v 由提案编号 p 决定，v′ 由提案编号 p′ 决定，则 v &#x3D; v′对于要确定的给定值 v，必须首先提出它。 因此，以下要求更加严格：定理 2. 如果值 v 由提案编号 p 决定，则对于任何消息 suggest(p’,v’)，其中 p’ &gt; p 则 v &#x3D; v’通过反证法证明，即假设v̸&#x3D;v′。 我们将考虑发送此类消息的最小提议编号 p’ &gt; p。令 Q1 和 Q2 分别为所有有效第 1 阶段和第 2 阶段法定人数的集合，A 为接受者集合。 法定人数有效，前提是：\n∀Q1 ∈Q1 :Q1 ⊆A (1) \t\t\t\t\t∀Q2 ∈Q2 :Q2 ⊆A (2) ∀Q1 ∈Q1,∀Q2 ∈Q2 :Q1 ∩Q2 ̸=∅ (3) \n\n公式 1 指定每个可能的阶段 1 仲裁都是接受器的子集，与公式 2 类似。公式 3 指定由阶段 1 和阶段 2 仲裁组成的所有可能组合将在至少一个接受器中相交。令 Qp,2 为提案编号 p 使用的第 2 阶段法定人数，Qp’,1 为提案编号 p’ 使用的第 1 阶段法定人数。 令 A ̄ 为同时参与提案编号 p 使用的第 2 阶段仲裁和提案编号 p′ 使用的第 1 阶段仲裁的接受者集合，因此 A ̄ &#x3D; Qp,2 ∩ Qp′,1。 由于 Qp,2 ∈ Q2 且 Qp′,1 ∈ Q1，因此我们可以使用等式 3 来推断至少有一个接受者必须参与两个群体，A ̄ ̸&#x3D; ∅。让我们从一个接受者 acc 的角度来考虑事件的排序，其中 acc ∈ A ̄。 他们要么先收到prepare(p’)，要么先收到propose(p,v)。 我们将分别考虑以下每种情况：情况1：接受器 acc 在接收 suggest(p,v) 之前先接收prepare(p’)。 当 acc 收到 propose(p,v) 时，其最后承诺的提案将为 p’ 或更高。 当 p′ &gt; p 时，它不会接受来自 p 的提议，然而，当 acc ∈ Qp,2 时，它必须接受提议(p,v)。 这是一个矛盾，因此不可能是这样。情况2： 接受器 acc 在接收prepare(p’)之前接收propose(p,v)。 当acc接收到prepare(p’)时，有两种情况。 任何一个：情况 2a： 接受者 acc 最后承诺的提案已经高于 p’。 那么它不会接受来自 p’ 的准备，但是由于 acc ∈ Qp’,1 它必须接受准备（p’）。 这是一个矛盾，因此不可能是这样。情况 2b： 接受者 acc 最后承诺的提案小于 p′，那么它将回复 Promise(q,v)，其中 p ≤ q &lt; p′。 在 p’ 的极小假设下，v 值将与 p 接受的值相同。acc ∈ Qp′,1 因此promise(q,v)将至少是p′的提议者收到的响应之一。 如果这是唯一接受的返回值，则将选择其值 v。 Qp’,1 成员还可能收到其他提案。 回想一下 p &lt; p′。 对于收到的每个其他提案 (q′,v′′)，可以：CASE (i) q′ &lt; q：这些提案将被忽略，因为提案者必须选择与最高提案相关的值。CASE (ii) p′ &lt; q′：这种情况不会发生，因为接受者只有在最后承诺的值 &lt; p′ 时才会回复prepare(p′)。图 4：具有不同仲裁大小和 LibPaxos3 的 FPaxos 的吞吐量和平均延迟。CASE (iii) p &lt; q′ &lt; p′ ：对于接受者来说，要接受 (q′, v′′)，那么它必须首先被提议。 根据 p’ 的极小假设，这是不可能的。因此，将选择值 v，这与发送 suggest(p’, v’) 的假设相矛盾。我们在 TLA+ [20] 中提供了单值 FPaxos 协议的 2 页正式规范。 我们使用不相交的法定人数对该规范进行了模型检查，并保留了要求 2。 FPaxos TLA+ 规范只是 [20] 中给出的 Paxos 规范的一个小修改。\nPrototype我们通过修改 LibPaxos3 【LibPaxos3源代码 https://bitbucket.org/sciascid/libpaxos】（一种常用的基准测试 Multi-Paxos 实现）来实现一个简单的 FPaxos。 我们的修改只是概括了 Q1 和 Q2 的大小。 简单的法定人数是随机选择的，消息仅发送到法定人数的节点。LibPaxos3 是 C 语言的 Multi-Paxos 实现，它使用 TCP&#x2F;IP 进行传输。 对于每个实验，我们测试了 N 个副本，其中每个副本都是领导者、接受者和提议者。 我们使用的请求大小为 64 字节，在任何给定时间都有 10 个正在进行的请求。 我们的实验是在具有单核和 1GB RAM 的单个 Linux VM 中运行的，我们使用 mininet 【http://mininet.org】来模拟具有 20 ms 往返时间的 10 Mbps 网络。 每个测试运行 120 秒，我们丢弃前 10 秒和最后 10 秒来测量系统在稳定状态下的情况。图 4 显示了具有不同 Q2 仲裁大小的 Paxos 和 FPaxos 的稳态性能。 这些结果正如我们所期望的：通过减少 Q2 仲裁的大小，我们发送更少的消息，从而提高吞吐量并减少延迟。值得注意的是，这并不是完整的情况。 首先，即使仲裁大小相同，FPaxos 的性能也优于普通 LibPaxos，因为 FPaxos 仅将消息发送到仲裁的副本，而 LibPaxos3 则将消息发送到所有副本。 在实践中利用这种优化时，人们可能需要仔细权衡在实际设置中查找仲裁的策略，并考虑副本故障、相对副本速度和通信延迟。 其次，与 Paxos 不同的是，当两个接受者失败时，Q2 大小为 2 的 FPaxos 将无法选举新的领导者。 另一方面，在 8 个副本的系统中，Q2 大小为 4 的 FPaxos 比 Paxos 处理更多的故障，减少延迟（从 42 毫秒到 37 毫秒）并提高吞吐量（从 198 请求&#x2F;秒增加到 264 请求&#x2F;秒）。 这个原型证明了实现一个简单的 FPaxos 是微不足道的。 我们证明，即使是非常简单的实现也能提高性能，并且我们相信为 FPaxos 设计的系统将获得更高的性能，特别是通过利用不相交的接受器集和更智能的仲裁构建技术来提高容错能力。 我们的原型源代码和相关材料可在线获取【https://github.com/fpaxos】。\nEnhancements我们观察到 FPaxos 的安全性仅依赖于给定 Q1 将与具有较低提案编号的所有 Q2 相交的假设。 因此，如果提案者能够了解哪些 Q2 已使用较小的提案编号，我们可以进一步削弱法定人数要求。 然后，我们只要求提议者的 Q1 与这些而不是所有可能的 Q2 相交。为了利用这一点，我们可以通过领导者选择法定人数并宣布其选择的机制来增强 FPaxos。 实现这一点的方法有很多，但为了安全起见，领导者公开其法定人数选择的机制必须仔细地融入领导者选举协议中。 详细信息不属于本文的讨论范围。 简而言之，它类似于 Paxos 重新配置，并通过采用 Vertical Paxos [23] 的原理来实现。这种增强的影响可能是深远的。 例如，在 N &#x3D; 100f 个节点的系统中，领导者可能会首先宣布大小为 f + 1 的固定 Q2，并且所有更高的提案编号（和读者）将只需要与该 Q2 相交。 这使我们能够容忍 N − f 次失败。 同样，领导者可以选择一小组 Q2 并宣布所有这些，从而在第 2 阶段提供更大的灵活性，但代价是第 1 阶段的可用性较低。领导者还可以使用动态选择机制随着时间的推移更改其法定人数选择。我们预计这些增强功能和其他增强功能可能会为未来的实际系统设计带来许多新的可能性。\nRelated Works富有洞察力的状态机复制 (SMR) 范式 [17, 36] 是许多可靠系统的基础，包括分布式系统领域的开创性工作，如 Viewstamped Replication [32] 和 Isis [3]。 Paxos 算法为许多架构为复制状态机的生产系统提供了算法解决方案。 SMR 必须解决一个核心要素，即协议，Dwork 等人[6] 在最小同步假设下解决，这是 Paxos [18] 中单位置协议协议（称为 Synod）的基础。 在其发明后的几十年里，Paxos 算法得到了广泛的研究：它已经用更简单的术语进行了解释 [19, 39]，针对实际系统进行了优化 [4, 11, 13, 33]，并扩展到处理重新配置 [23] 和 任意失败[5]。人们提出了 Paxos 的许多变体。 Cheap Paxos [25] 固定单个阶段 2 法定人数，直到发生领导者替换。 Fast Paxos [21] 有一个无领导的快速路径协议，它利用大小为 f + [(f+1)&#x2F;2] 的快速通道第 2 阶段群体。 Mencius [26]采用循环领导制度。 Ring-Paxos [28, 27] 将 Cheap Paxos [25] 中的思想应用于使用网络级多播的环覆盖。 链复制[41]以菊花链（Daisy Chain）的方式连接接受器并将两个阶段合并为一个链扫描。 Generalized Paxos [22] 使用交换命令扩展了状态机复制，Egalarian Paxos [30] 使用大小为 f + [(f+1)&#x2F;2] 的快速通道仲裁扩展了 Generalized Paxos。 EVE [14] 乐观地同时同意命令，并在不通勤的情况下解决冲突。 Corfu [2] 让领导者将其专属权力委托给任何提议者，以产生更好的并行性。 还有许多其他变体； [40] 中给出了 Paxos 变体的综合分类。 这些先前的工作建立在开创性协议 [32,3,6,18] 中提出的基础上，并专注于增强它们以实现更好的性能。 我们的新观察重新审视了基础并对其进行了概括； 它是完全正交的，可以集成到以前的协议以及实际的生产系统中，以进一步提高性能。SMR 重新配置问题已在之前的几项工作中得到解决。 有些使用共识命令来就下一个配置达成一致[32,24,23]，而另一些则使用第一阶段来确定第二阶段将使用哪个仲裁（从一组固定的仲裁中）[25,28]。 [23] 中出现了将稳态一致机制与重新配置事件分开的重新配置的通用框架。 之前也研究过其他容错服务的重新配置，例如，在[10,1,12,38,8]中。 正如第 7 节中所讨论的，可以采用这些工作中的想法来将 FPaxos 增强为可重构的动态系统。 据我们所知，我们是第一个证明并实现 Paxos 泛化的人。 在准备本出版物期间，Sougoumarane 独立地进行了与本工作相同的观察，并发布了一篇博客文章，为系统社区总结了它 [37]。\nConclusion在本文中，我们描述了 FPaxos，它是广泛采用的 Paxos 算法的泛化，它不再要求来自同一 Paxos 相位的群体相交。 我们相信这一结果会产生广泛的影响。首先，在过去的二十年里，Multi-Paxos 得到了广泛的研究、部署和扩展。 推广现有系统以使用 FPaxos 应该非常简单。 向开发人员公开复制（第 2 阶段）仲裁大小将允许他们在容错和稳态延迟之间选择自己的权衡。其次，通过不再要求复制仲裁相交，我们消除了可扩展性的重要限制。 通过智能仲裁构建和务实的系统设计，我们相信新型可扩展、有弹性和高性能的共识算法现在是可能的。致谢。 我们要感谢以下人员的反馈：Jean Bacon、Jon Crowcroft、Stephen Dolan、Matthew Grosvenor、Anil Madhavapeddy、Sugu Sougoumarane 和 Igor Zabloctchi。\nReferences[1] Marcos K. Aguilera、Idit Keidar、Dahlia Malkhi 和 Alexander Shraer。 没有共识的动态原子存储。 J. ACM，58(2):7:1–7:32，2011 年 4 月。URL：http://doi.acm.org/10.1145/1944345.1944348，doi：10.1145&#x2F;1944345.1944348。[2] Mahesh Balakrishnan、Dahlia Malkhi、John D. Davis、Vijayan Prabhakaran、Michael Wei 和 Ted Wobber。 Corfu：分布式共享日志。 ACM 翻译。 计算。 系统，31(4):10:1–10:24，2013 年 12 月。[3] 肯·伯曼和托马斯·约瑟夫。 在分布式系统中利用虚拟同步，第 21 卷。ACM，1987 年。[4] 迈克·伯罗斯。 用于松散耦合分布式系统的胖乎乎的锁服务。 第七届操作系统设计与实现研讨会论文集，OSDI ’06，第 335-350 页，美国加利福尼亚州伯克利，2006 年。USENIX 协会。 网址：http://dl.acm.org/itation.cfm?id=1298455.1298487。[5] 米格尔·卡斯特罗和芭芭拉·利斯科夫。 实用的拜占庭容错。 在第三届操作系统设计和实现研讨会论文集，OSDI ‘99，第 173-186 页，美国加利福尼亚州伯克利，1999 年。USENIX 协会。 网址：http://dl.acm.org/itation.cfm?id=296806.296824。[6] 辛西娅·德沃克、南希·林奇和拉里·斯托克迈尔。 存在部分同步的情况下达成共识。 美国计算机协会杂志 (JACM)，35(2)：288–323，1988 年。[7] 迈克尔·J·费舍尔、南希·A·林奇和迈克尔·S·帕特森。 不可能通过一个错误的流程达成分布式共识。 美国计算机协会杂志 (JACM)，32(2)：374–382，1985 年。[8] 伊莱·加夫尼和达丽娅·马尔基。 通过简约的推测快照解决方案进行弹性配置维护。 第 29 届国际分布式计算研讨会论文集，第 140-153 页。 施普林格，2015。[9] 大卫·K·吉福德。 对复制数据进行加权投票。 第七届 ACM 操作系统原理研讨会论文集，SOSP ’79，第 150–162 页，美国纽约州纽约市，1979 年。ACM。 网址：http://doi.acm。 org&#x2F;10.1145&#x2F;800215.806583，doi：10.1145&#x2F;800215.806583。[10] 塞斯·吉尔伯特、南希·A·林奇和亚历山大·A·什瓦茨曼。 Rambo：用于动态网络的强大的、可重新配置的原子内存服务。 分布式计算，23(4)：225–272，2010。[11]帕特里克·亨特、马哈德夫·科纳尔、弗拉维奥·P·容奎拉和本杰明·里德。 Zookeeper：互联网规模系统的无等待协调。 2010 年 USENIX 会议记录，关于 USENIX 年度技术会议，USENIXATC’10，第 11-11 页，伯克利，加利福尼亚州，美国，2010 年。USENIX 协会。 网址：http://dl.acm.org/itation.cfm?id=1855840.1855851。[12] Leander Jehl、Roman Vitenberg 和 Hein Meling。 Smartmerge：原子存储重新配置的新方法。 国际分布式计算研讨会，第 154-169 页。 施普林格，2015。[13] 弗拉维奥·P·朱奎拉、本杰明·C·里德和马可·塞拉菲尼。 Zab：用于主备份系统的高性能广播。 可靠系统与网络 (DSN)，2011 年 IEEE&#x2F;IFIP 第 41 届国际会议，第 245-256 页。 IEEE，2011。[14] Manos Kapritsos、Yang Wang、Vivien Quema、Allen Clement、Lorenzo Alvisi 和 Mike Dahlin。 关于 eve：多核服务器的执行验证复制。 作为第 10 届 USENIX 操作系统设计和实现研讨会 (OSDI 12) 的一部分，第 237-250 页，2012 年。[15]阿基尔·库马尔。 分层仲裁共识：一种管理复制数据的新算法。 IEEE 传输。 计算机，40(9):996–1004，1991 年 9 月。URL：http://dx.doi.org/10.1109/12.83661，doi:10.1109&#x2F;12.83661。[16]莱斯利·兰波特。 可靠的分布式多进程系统的实现。 计算机网络 (1976), 2(2):95 – 114, 1978。doi:http://dx.doi.org/10.1016/0376-5075(78)90045-4。[17]莱斯利·兰波特。 分布式系统中的时间、时钟和事件顺序。 ACM 通讯，21(7):558–565, 1978。[18]莱斯利·兰波特。 兼职议会。 ACM 翻译。 计算。 系统，16(2):133–169，1998 年 5 月。URL：http://doi.acm.org/10.1145/279227。 279229，doi：10.1145&#x2F;279227.279229。[19] 莱斯利·兰波特。 Paxos 变得简单。 ACM SIGACT 新闻（分布式计算专栏），2001 年。[20]莱斯利·兰波特。 指定系统：面向硬件和软件工程师的 TLA+ 语言和工具。 Addison-Wesley Longman Publishing Co., Inc.，美国马萨诸塞州波士顿，2002 年。[21] 莱斯利·兰波特。 快速 paxos。 技术报告 MSR-TR-2005-112，微软研究院，2005 年。[22] 莱斯利·兰波特。 广义共识和 paxos。 技术报告 MSR-TR-2005-33，微软研究院，2005 年 3 月。[23] 莱斯利·兰波特、达丽娅·马尔基和周立东。 垂直 paxos 和主备复制。 第 28 届 ACM 分布式计算原理研讨会论文集，PODC ‘09，第 312-313 页，美国纽约州纽约市，2009 年。ACM。 网址：http://doi.acm.org/10.1145/1582716。 1582783，doi：10.1145&#x2F;1582716.1582783。[24] 莱斯利·兰波特、达丽娅·马尔基和周立东。 重新配置状态机。 ACM SIGACT 新闻，41(1):63–73，2010。[25] 莱斯利·兰波特和迈克·马萨。 便宜的paxos。 2004 年可靠系统和网络国际会议记录，DSN ’04，第 307 页，美国华盛顿特区，2004 年。IEEE 计算机协会。 网址：http://dl.acm.org/itation.cfm?id=1009382.1009745。[26] 毛燕华，Flavio P. Junqueira，和 Keith Marzullo。 孟子：为广域网构建高效的复制状态机。 第八届 USENIX 操作系统设计与实现会议论文集，OSDI’08，第 369–384 页，美国加利福尼亚州伯克利，2008 年。USENIX 协会。 网址：http://dl.acm.org/itation.cfm?id=1855741.1855767。[27] 帕里萨·贾利利·马兰迪、马可·普里米和费尔南多·佩多内。 多环 paxos。 IEEE&#x2F;IFIP 国际可靠系统和网络会议 (DSN 2012)，第 1-12 页。 IEEE，2012。[28] Parisa Jalili Marandi、Marco Primi、Nicolas Schiper 和 Fernando Pedon。 Ring paxos：一种高吞吐量原子广播协议。 2010 年 IEEE&#x2F;IFIP 国际可靠系统和网络会议 (DSN)，第 527-536 页。 IEEE，2010。[29] P.J. Marandi、M. Primi、N. Schoper 和 F. Pedone。 Ring Paxos：一种高吞吐量原子广播协议。 可靠系统和网络 (DSN)，2010 年 IEEE&#x2F;IFIP 国际会议，第 527–536 页，2010 年 6 月。doi:10.1109&#x2F;DSN.2010.5544272。[30] 尤利安·莫拉鲁、大卫·G·安德森和迈克尔·卡明斯基。 平等主义议会中有更多共识。 第二十四届 ACM 操作系统原理研讨会论文集，SOSP ‘13，第 358–372 页，美国纽约州纽约市，2013 年。ACM。 网址：http://doi.acm.org/10。 1145&#x2F;2517349.2517350，doi：10.1145&#x2F;2517349.2517350。[31] 莫尼·纳尔和阿维沙伊·伍尔。 仲裁系统的负载、容量和可用性。 SIAM J. Comput.，27(2):423–447，1998 年 4 月。URL：http://dx.doi.org/10.1137/S0097539795281232，doi:10.1137&#x2F;S0097539795281232。[32] 布莱恩·M·奥基 (Brian M Oki) 和芭芭拉·H·利斯科夫 (Barbara H Liskov)。 Viewstamped 复制：一种新的主复制方法，支持高可用性的分布式系统。 第七届年度 ACM 分布式计算原理研讨会论文集，第 8-17 页。 美国计算机学会，1988。[33]迭戈·翁加罗和约翰·奥斯特豪特。 寻找一种可理解的共识算法。 在过程中。 USENIX 年度技术会议，第 305-320 页，2014 年。[34] 大卫·法勒和阿维沙伊·伍尔。 摇摇欲坠的墙：一类实用且高效的法定人数系统。 第十四届年度 ACM 分布式计算原理研讨会论文集，PODC ‘95，第 120-129 页，美国纽约州纽约市，1995 年。ACM。 网址：http://doi.acm.org/10。 1145&#x2F;224964.224978，doi：10.1145&#x2F;224964.224978。[35] 弗雷德·B·施奈德。 使用状态机方法实现容错服务：教程。 ACM 计算。 Surv.，22(4)：299–319，1990 年 12 月。URL：http://doi.acm.org/10.1145/98163.98167，doi：10.1145&#x2F;98163.98167。[36] 弗雷德·B·施奈德。 使用状态机方法实现容错服务：教程。 ACM 计算调查 (CSUR)，22(4)：299–319，1990。[37] 苏古·索古玛拉内。 更灵活的paxos。 http://ssougou.blogspot。 com&#x2F;2016&#x2F;08&#x2F;a-more-flexible-paxos.html。 [在线的; 2016 年 8 月 13 日访问]。[38] 亚历山大·斯皮格曼、伊迪特·凯达尔和达丽娅·马尔基。 动态重新配置：教程。 OPODIS 2015，2015。[39] 罗伯特·范·雷内斯和德尼兹·阿尔廷布肯。 Paxos 变得中等复杂。 ACM 计算。 Surv.，47(3):42:1–42:36，2015 年 2 月。URL：http://doi.acm.org/10.1145/2673577，doi：10.1145&#x2F;2673577。[40] 罗伯特·范·雷内斯和德尼兹·阿尔廷布肯。 Paxos 变得中等复杂。 ACM 计算。 Surv.，47(3):42:1–42:36，2015 年 2 月。URL：http://doi.acm.org/10.1145/2673577，doi：10.1145&#x2F;2673577。[41] 罗伯特·范·雷内斯和弗雷德·B·施奈德。 链式复制支持高吞吐量和可用性。 OSDI，第 4 卷，第 91-104 页，2004 年。 \t \n","tags":["分布式共识算法"]},{"title":"Integrate RocketMQ 5.0 client with Spring - 记录本次开发的思考与实践","url":"/2023/10/20/Integrate%20RocketMQ%205.0%20client%20with%20Spring%20-%20%E8%AE%B0%E5%BD%95%E6%9C%AC%E6%AC%A1%E5%BC%80%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83%E4%B8%8E%E5%AE%9E%E8%B7%B5/","content":"前言RocketMQ-Spring 目前已经支持了4.x Remoting SDK，我们还需要支持RocketMQ 5.0 gRPC SDK，即是对 rocketmq-clients-SDK 进行封装和整合，最终以 rocketmq-spring-v5-starter 的形式呈现给用户。\nSpring 中的消息框架Spring Messaging 是Spring Framework 4中添加的模块，是Spring与消息系统集成的一个扩展性的支持。它实现了从基于JmsTemplate的简单的使用JMS接口到异步接收消息的一整套完整的基础架构，Spring AMQP提供了该协议所要求的类似的功能集。 在与Spring Boot的集成后，它拥有了自动配置能力，能够在测试和运行时与相应的消息传递系统进行集成。单纯对于客户端而言，Spring Messaging 提供了一套抽象的 API 或者说是约定的标准，对消息发送端和消息接收端的模式进行规定，不同的消息中间件提供商可以在这个模式下提供自己的Spring实现：在消息发送端需要实现的是一个 XXXTemplate 形式的 Java Bean，结合 Spring Boot 的自动化配置选项提供多个不同的发送消息方法；在消息的消费端是一个 XXXMessageListener 接口（实现方式通常会使用一个注解来声明一个消息驱动的 POJO），提供回调方法来监听和消费消息，这个接口同样可以使用Spring Boot的自动化选项和一些定制化的属性。参考 Spring Messaging 的既有实现，RocketMQ的 spring-boot-starter 中遵循了相关的设计模式并结合 RocketMQ 自身的功能特点提供了相应的API (如，顺序，异步和事务半消息等)。\n模块与适配按照 Spring Boot 的规范，原有的 4.X SDK 划分为四个子模块，我们 v5 SDK 也将延用分成四个子模块的方式完成开发，在这一点上，会参考 4.X 的模块设计。\n\nrocketmq-v5-client-spring-boot-parent （父pom文件，定义相关的依赖管理和Plugin，供其它几个模块引用）\nrocketmq-v5-client-spring-boot (定义 auto-configuration 实现，具体RocketMQ相关的自动配置和 Bean 创建代码都集中在这里)\nrocketmq-v5-client-spring-starter (将 rocketmq-v5-client-spring-boot 和其它的依赖打包生成全量的依赖，用户引用它即可完成所有 rocketmq-spring 的客户端操作)\nrocketmq-v5-client-spring-samples (使用示例，展示如何使用 spring-boot 方式发送和消费消息)\n\n为了更方便理解模块之间的依赖关系，我做了一个模块依赖图，图示如下，其中rocketmq-grpc-spring-boot-parent 等含有 grpc 写法皆代表 v5 模块，就不再更改了。可以看到，我们在rocketmq-spring-all项目顶级模块之下，又开发了rocketmq-grpc-spring-boot-parent 新模块，他是我们其他 maven 子模块的父模块。所有的子模块都继承于父模块，项目中所有要使用到的 jar 包的版本都集中由父工程管理。 rocketmq-grpc-spring-boot-starter 会发布到maven仓库中，用户需要使用时只需要引入这个 starter 即可使用。\n设计思路\n添加maven依赖项目需在 pom.xml 文件中引入SDK5.0 依赖 rocketmq-client-java 依赖，并且设置 rocketmq-client-java-version 最新版本\n&lt;dependency&gt;  &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;  &lt;artifactId&gt;rocketmq-client-java&lt;/artifactId&gt;  &lt;version&gt;$&#123;rocketmq-client-java-version&#125;&lt;/version&gt;&lt;/dependency&gt; \n\n\n适配spring-boot自动化配置\n支持适配新客户端实体目前 rocketmq-spring 中基于 4.x SDK 实现的自动配置类主要是两个bean：\npublic static final String PRODUCER_BEAN_NAME = &quot;defaultMQProducer&quot;;public static final String CONSUMER_BEAN_NAME = &quot;defaultLitePullConsumer&quot;;\n\n引入 v5-sdk 之后，在 template 中需要加入 IOC 容器进行管理的有以下几个bean：\nprivate ProducerBuilder producerBuilder;private SimpleConsumerBuilder simpleConsumerBuilder;private Producer producer;private SimpleConsumer simpleConsumer;\n\n在确定好我们需要进行控制反转注入ioc容器的bean有哪些后，就要考虑如何将他们交给ioc容器管理。按照目前rocketmq-spring给出的@Configuration+@Bean注解的方式，我们同样可以利用这些注解来进行对producer、pushConsumer和simpleConsumer进行管理。但是 PushConsumer 需要交给 DefaultListenerContainer 容器进行管理，而不是放到 RocketMQGRpcTemplate容器中。这里为什么要让 IOC 容器管理额外的 builder 对象（像ProducerBuilder、SimpleConsumerBuilder 以及DefaultListenerContainer容器中的 PushConsumerBuilder），⽽不是只管理调⽤build()⽅法之后构建的3个真正的⽣产消费者实体bean， 乃是基于以下的考量： 我们在RocketMQAutoConfiguration这个⾃动配置类中，需要构造producer和consumer，但是此时我 们的producer尚不是⼀个完整的producer，因为如果⽤户要发送事务消息，是需要设置⼀个 TransactionChecker.\nProducerBuilder setTransactionChecker(TransactionChecker checker);\n\n也就是说，如果我们在 RocketMQAutoConfiguration ⾥⾯构建bean时，就调⽤build⽅法去构建⼀个完整的 producer 对象，那么⽤户在使⽤我们的核⼼类 RocketmqTemplate 使⽤⽣产者发送事务消息时就只 能传⼊⼀个 TransactionChecker 的实现类作为参数去设置Producer的transactionChecker 属性，⽽ Producer ⼀旦被 build 构建，我们是⽆法再去修改的，所以在 RocketMQAutoConfiguration ⾥⾯构建 bean 时只能构建⼀个ProducerBuilder，等待⽤户实现的 TransactionChecker 参数设置进去。 同理的，我们的pushConsumer也是需要⼀个回调函数去处理 MessageView 的逻辑，所以这⾥也是需要先构建好⼀个builder，最后等到所有参数注⼊完成后才可以再去调⽤build⽅法⽣成⼀个真正的实例。\n装配Producer我们需要实现对 5.0SDK 中的Producer进⾏管理：(1)引⼊Producer属性的配置类我们通过在RocketMQProperties类中定义我们的Producer实例引⼊的配置⽂件的配置\npublic static class Producer &#123; /** * The property of &quot;access-key&quot;. */ private String accessKey; /** * The property of &quot;secret-key&quot;. */ private String secretKey; /** * Proxy address and port list */ private String endpoints; /** * topic is used to prefetch the route */ private String topic;//此处省略对应的getter/setter代码 &#125;\n\n\n代码实现首先我们需要对 5.0 SDK 中的 producer 进行管理，通过 RocketMQProperties 引入的参数直接对 producer 进行构造。\n/** * description:gRPC-SDK ProducerBuilder */@Bean(PRODUCER_BUILDER_BEAN_NAME)@ConditionalOnMissingBean(ProducerBuilderImpl.class)@ConditionalOnProperty(prefix = &quot;rocketmq&quot;, value = &#123;&quot;producer.endpoints&quot;&#125;)public ProducerBuilder producerBuilder(RocketMQProperties rocketMQProperties) &#123;    RocketMQProperties.Producer rocketMQProducer = rocketMQProperties.getProducer();    log.info(&quot;Init Producer Args: &quot; + rocketMQProducer);    String topic = rocketMQProducer.getTopic();    String endPoints = rocketMQProducer.getEndpoints();    Assert.hasText(endPoints, &quot;[rocketmq.producer.endpoints] must not be null&quot;);    ClientConfiguration clientConfiguration = RocketMQUtil.createProducerClientConfiguration(rocketMQProducer);    final ClientServiceProvider provider = ClientServiceProvider.loadService();    ProducerBuilder producerBuilder;    producerBuilder = provider.newProducerBuilder()            .setClientConfiguration(clientConfiguration)            // Set the topic name(s), which is optional but recommended. It makes producer could prefetch the topic            // route before message publishing.            .setTopics(rocketMQProducer.getTopic())            .setMaxAttempts(rocketMQProducer.getMaxAttempts());    log.info(String.format(&quot;a producer init on proxy %s&quot;, endPoints));    return producerBuilder;&#125;\n\n可以看到，由于需要⽀持 v5 版本的 producer，与原有 4.x 的内部类 Producer 不同，换新了以下字段：\n\nEndpoints字段：我们知道endpoints是接⼊点地址，需要设置成Proxy的地址和端⼝列表。RocketMQ Proxy的出现，解决了4.X版本客户端多语⾔客户端实现Remoing协议难度⼤、复杂、功能不⼀致、维护⼯作⼤的问题。使⽤业界熟悉的gRPC协议， 各个语⾔代码统⼀、简单，使得多语⾔使⽤RocketMQ更⽅便容易。\nTopic字段：在4.x SDK的Producer中，我们通常在messge中设置topic，⽽不在producer中直接设置topic。但是在5.0 SDK中，我们既可以在producer，也可以在message中指定topic。这样做的好处是，⽣产者能够在发送消息之前预先获取该主题的路由信息，并缓存到本地。这样，当⽣产者要发送消息时，它就可以直接从本地缓存中获取路由信息，避免了每次发送消息都需要进⾏路由查找的问题，从⽽提升了发送消息的效率和性能。\n\n(2)加⼊配置属性注解在RocketMQProperties上加⼊注解@ConfigurationProperties(prefix &#x3D; “rocketmq”)，能够引⼊配置⽂件中的⽤户⾃定义属性。\n@ConfigurationProperties(prefix = &quot;rocketmq&quot;)public class RocketMQProperties &#123;    &#125;\n\n(3)注⼊bean我们需要在 RocketMQAutoConfiguration 中配置交给 IOC 容器管理的 bean，这⾥的 bean 只能是⼀个 ProducerBuilder，⽽不是 Producer，具体原因在上⽂已经阐述。\n/** * description:gRPC-SDK PushConsumer */@Bean(PUSH_CONSUMER_BEAN_NAME)@ConditionalOnMissingBean(PushConsumerBuilder.class)@ConditionalOnProperty(name = &quot;rocketmq.sdk-version&quot;, havingValue = &quot;grpc&quot;)//@ConditionalOnProperty(prefix = &quot;rocketmq&quot;, value = &#123;&quot;producer.endpoints&quot;&#125;)public PushConsumerBuilder pushConsumerBuilder(RocketMQProperties rocketMQProperties) &#123;    //此处getConsumer返回一个pushConsumer,getPullConsumer返回一个pullConsumer    RocketMQProperties.PushConsumer rocketMQPushConsumer = rocketMQProperties.getConsumer();    final ClientServiceProvider provider = ClientServiceProvider.loadService();    SessionCredentialsProvider sessionCredentialsProvider =            new StaticSessionCredentialsProvider(rocketMQPushConsumer.getAccessKey(), rocketMQPushConsumer.getSecretKey());    ClientConfiguration clientConfiguration = ClientConfiguration.newBuilder()            .setEndpoints(rocketMQPushConsumer.getEndpoints())            .setCredentialProvider(sessionCredentialsProvider)            .build();    FilterExpression filterExpression = new FilterExpression(rocketMQPushConsumer.getTag(), FilterExpressionType.TAG);    final PushConsumerBuilder builderImpl;    builderImpl = provider.newPushConsumerBuilder()            .setClientConfiguration(clientConfiguration)            // Set the consumer group name.            .setConsumerGroup(rocketMQPushConsumer.getGroup())            // Set the subscription for the consumer.            .setSubscriptionExpressions(Collections.singletonMap(rocketMQPushConsumer.getTopic(), filterExpression));    return builderImpl;&#125;\n\n(4)配置加载执⾏的先后顺序我们可以看到在RocketMQAutoConfiguration这个类上有以下注解，表明RocketMQAutoConfiguration 需要在TransactionConfiguration之前被加载和执⾏\n@AutoConfigureBefore(&#123;TransactionConfiguration.class&#125;)\n\n(5)引⼊事务处理注解我们也需要⼀个⾃定义的 TransactionConfiguration 配置类，⽤来注⼊我们刚刚所说的，⽣产者所需要的 TransactionChecker 来执⾏回调函数。⾸先我们实现SmartInitializingSingleton 接⼝，在bean初始化完成后执⾏⼀些初始化操作：获取被@RocketMQTransactionListener 标记的类，这个类是需要⽤户实现TransactionChecker 接⼝的，handleTransactionChecker ⽅法会⾃动将这个实现类给注⼊到 rocketmqTemplate 管理的 ProducerBuilder 对象中。这⾥的 template 是根据 @RocketMQTransactionListener注解中的rocketMQTemplateBeanName 值来从容器上下⽂中提取的，template 是可拓展的，也就是我们所说的 @ExtTemplateConfiguration\n        @Configuration        public class TransactionConfiguration implements ApplicationContextAware,                SmartInitializingSingleton &#123;            private ConfigurableApplicationContext applicationContext;            @Override            public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;                this.applicationContext = (ConfigurableApplicationContext) applica                tionContext;            &#125;            //获取被@RocketMQTransactionListener标记的类            @Override            public void afterSingletonsInstantiated() &#123;                Map&lt;String, Object&gt; beans = this.applicationContext.getBeansWithAn                notation(TransactionListener.class)                        .entrySet().stream().filter(entry -&gt; !ScopedProxyUtils.isS                                copedTarget(entry.getKey()))                        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::ge                                tValue));                beans.forEach(this::handleTransactionChecker);            &#125;            public void handleTransactionChecker(String beanName, Object bean) &#123;                Class&lt;?&gt; clazz = AopProxyUtils.ultimateTargetClass(bean);                if (!TransactionChecker.class.isAssignableFrom(bean.getClass())) &#123;                    throw new IllegalStateException(clazz + &quot; is not instance of &quot;                            + TransactionChecker.class.getName());                &#125;                TransactionListener annotation = clazz.getAnnotation(TransactionLi                        stener.class);                if (Objects.isNull(annotation)) &#123;                    throw new IllegalStateException(&quot;The transactionListener annot                            ation is missing&quot;);                &#125;                //获取注解上的template,默认为RocketMQGRpcTemplate                RocketMQGRpcTemplate rocketMQTemplate = (RocketMQGRpcTemplate) app                licationContext.getBean(annotation.rocketMQTemplateBeanName());                if ((rocketMQTemplate.getProducerBuilder()) != null) &#123;                    rocketMQTemplate.getProducerBuilder().setTransactionChecker((T                            ransactionChecker) bean);                &#125;            &#125;        &#125;\n\n(6)⽣产者拓展的实现我们可以⽤⼀个 @ExtTemplateConfiguration 注解来拓展我们的rocketmqTemplate，当⽤户需要多个不同的⽣产者时，可以使⽤这个注解来拓展装配不同的⽣产者。\n@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface ExtTemplateConfiguration &#123;    /**     * The component name of the Producer configuration.     */    String value() default &quot;&quot;;    /**     * The property of &quot;access-key&quot;.     */    String accessKey() default &quot;$&#123;rocketmq.producer.accessKey:&#125;&quot;;    /**     * The property of &quot;secret-key&quot;.     */    String secretKey() default &quot;$&#123;rocketmq.producer.secretKey:&#125;&quot;;    /**     * Proxy address and port list     */    String endpoints() default &quot;$&#123;rocketmq.producer.endpoints:&#125;&quot;;    /**     * topic is used to prefetch the route     */    String topic() default &quot;$&#123;rocketmq.producer.topic:&#125;&quot;;&#125;\n\n(7)容器拓展类的注册对于这个拓展 ExtRocketmqTemplate 的装配，我们可以在⾃定义配置类ExtProducerResetConfiguration 中构造。与上⽂中 TransactionConfiguration 配置类似的，⾸先获取 @ExtTemplateConfiguration 注解下的所有 bean，然后获取@ExtTemplateConfiguration 注解的所有拓展属性值，装配出⼀个 ProducerBuilder并注⼊到⾃定义的拓展 ExtRocketmqTemplate 中。\n新增字段由于在 rocketmq-spring 的基于 4.x remoting 的源代码中，RocketMQProperties 类中的静态内部类 PushConsumer 是继承 PullConsumer 的，所以我在 PullConsumer 的字段中加入了以下两个属性：Tag属性：设置消息 Tag，用于消费端根据指定Tag过滤消息EndPoints属性：同上 Producer 的 Endpoints 介绍：我们知道 endpoints 是接入点地址，需要设置成 Proxy 的地址和端口列表。有了 RocketMQ Proxy 的出现，无疑解决了4.X版本客户端多语言客户端实现 Remoing 协议难度大、复杂、功能不一致、维护工作大的问题。使用业界熟悉的GRPC协议， 各个语言代码统一、简单，使得多语言使用RocketMQ更方便容易。FilterExpressionType属性：消费者过滤表达式的类型。RocketMQ 支持两种过滤表达式类型：TAG 和 SQL92。如果将 FilterExpressionType 设置为 TAG，则消费者只会消费指定标签的消息TAG 表达式类型比较简单，性能相对较好，适用于只需要简单标签过滤的场景。如果将 FilterExpressionType 设置为 SQL92，则消费者可以使用 SQL92 的语法来过滤消息。SQL92 表达式类型更加灵活，可以支持更复杂的过滤规则，但是由于需要解析 SQL92 语法，所以性能相对较差。我们可以根据实际情况，选择合适的过滤表达式类型可以提高消费者的性能和效率。\n/** * Tag of consumer. */private String tag;/** * Proxy address and port list */private String endpoints;/** * filterExpressionType */private String filterExpressionType = &quot;tag&quot;;\n\n\n装配SimpleConsumer\n代码实现/** * description:gRPC-SDK SimpleConsumer */@Bean(SIMPLE_CONSUMER_BEAN_NAME)@ConditionalOnMissingBean(SimpleConsumer.class)//@ConditionalOnProperty(name = &quot;rocketmq.sdk-version&quot;, havingValue = &quot;grpc&quot;)@ConditionalOnExpression(&quot;$&#123;rocketmq.sdk-version&#125; == &#x27;grpc&#x27; &amp;&amp; $&#123;rocketmq.pull-consumer.endpoints&#125;&quot;)//@ConditionalOnProperty(prefix = &quot;rocketmq&quot;, value = &#123;&quot;producer.endpoints&quot;&#125;)public SimpleConsumer simpleConsumer(RocketMQProperties rocketMQProperties) &#123;    //此处getConsumer返回一个pushConsumer,getPullConsumer返回一个pullConsumer    RocketMQProperties.PullConsumer rocketMQPullConsumer = rocketMQProperties.getPullConsumer();    final ClientServiceProvider provider = ClientServiceProvider.loadService();    SessionCredentialsProvider sessionCredentialsProvider =            new StaticSessionCredentialsProvider(rocketMQPullConsumer.getAccessKey(), rocketMQPullConsumer.getSecretKey());    ClientConfiguration clientConfiguration = ClientConfiguration.newBuilder()            .setEndpoints(rocketMQPullConsumer.getEndpoints())            .setCredentialProvider(sessionCredentialsProvider)            .build();    Duration awaitDuration = Duration.ofSeconds(30);    FilterExpressionType filterExpression = &quot;tag&quot;.equals(rocketMQPullConsumer.getTag()) ? FilterExpressionType.TAG : FilterExpressionType.SQL92;    FilterExpression expression = new FilterExpression(rocketMQPullConsumer.getTag(), filterExpression);    SimpleConsumer simpleConsumer;    try &#123;        simpleConsumer = provider.newSimpleConsumerBuilder()                .setClientConfiguration(clientConfiguration)                // Set the consumer group name.                .setConsumerGroup(rocketMQPullConsumer.getGroup())                // set await duration for long-polling.                .setAwaitDuration(awaitDuration)                // Set the subscription for the consumer.                .setSubscriptionExpressions(Collections.singletonMap(rocketMQPullConsumer.getTopic(), expression))                .build();    &#125; catch (ClientException e) &#123;        throw new RuntimeException(e);    &#125;    return simpleConsumer;&#125;\n\n\n新增字段同PushConsumer\n注解控制实体装配@ConditionalOnExpression(&quot;$&#123;rocketmq.sdk-version&#125; == &#x27;grpc&#x27; &amp;&amp; $&#123;rocketmq.pull-consumer.endpoints&#125;&quot;)\n\n@ConditionalOnExpression注解表示：只有当用户自定义配置属性rocketmq.sdk-version为grpc时，并且属性rocketmq.pull-consumer.endpoints不为空，才会将这个bean交给ioc容器管理，否则不会加载它。\n封装消息发送方法我们知道，RocketMQ-Spring 是遵循Spring Messaging API规范的，RocketMQ-Spring 通过实现 RocketMQTemplate 完成消息的发送。RocketMQTemplate 继承 AbstractMessageSendingTemplate 抽象类，来支持 Spring Messaging API 标准的消息转换和发送方法，这些方法最终会代理给 doSend 方法，doSend 方法会最终调用 syncSend，由 DefaultMQProducer 实现。\nremoting SDK消息发送首先我们先来分析一下基于rocketmq 4.x remoting SDK的消息发送封装类型：\n同步消息的发送//同步模式发送延迟消息（自定义超时时间）private SendResult syncSend(String destination, Message&lt;?&gt; message, long timeout, long delayTime, DelayMode mode)//同步模式发送延迟消息（自定义超时层级）public SendResult syncSend(String destination, Message&lt;?&gt; message, long timeout, int delayLevel)//同步模式发送批量消息public &lt;T extends Message&gt; SendResult syncSend(String destination, Collection&lt;T&gt; messages, long timeout)\n\n\n异步消息的发送//异步模式发送延迟消息public void asyncSend(String destination, Message&lt;?&gt; message, SendCallback sendCallback, long timeout, int delayLevel)//异步模式发送延迟批量消息public &lt;T extends Message&gt; void asyncSend(String destination, Collection&lt;T&gt; messages, SendCallback sendCallback, long timeout)\n\n\n顺序消息的发送//同步模式发送顺序延迟消息public SendResult syncSendOrderly(String destination, Message&lt;?&gt; message, String hashKey, long timeout, int delayLevel)//同步模式发送批量顺序延迟消息public &lt;T extends Message&gt; SendResult syncSendOrderly(String destination, Collection&lt;T&gt; messages, String hashKey, long timeout) &#123;//异步模式发送顺序延迟消息public void asyncSendOrderly(String destination, Message&lt;?&gt; message, String hashKey, SendCallback sendCallback, long timeout, int delayLevel)\n\n\n单向消息的发送//单向模式的消息发送，忽略响应public void sendOneWay(String destination, Message&lt;?&gt; message)//单向模式的消息顺序发送，忽略响应public void sendOneWayOrderly(String destination, Message&lt;?&gt; message, String hashKey)\n\n\n事务消息的发送//事务消息的发送public TransactionSendResult sendMessageInTransaction(final String destination, final Message&lt;?&gt; message, final Object arg)\n\n\nRequest-Reply 消息的发送Request-Reply 消息指的是上游服务投递消息后进入等待被通知的状态，直到消费端返回结果并返回给发送端。\n//Request-Reply 消息发送public &lt;T&gt; T sendAndReceive(String destination, Message&lt;?&gt; message, Type type, String hashKey,long timeout, int delayLevel)\n\n\nv5 SDK消息发送基于上述remoting SDK消息的发送，我们需要进一步整合进 v5 SDK到 rocketmq-spring中。在rocketmq-client-java项目中，我们依据Producer接口下的方法，首先可以粗略地将生产者发送消息的方法归结为以下三类：（1）Producer发送同步消息：\nSendReceipt send(Message message) throws ClientException;\n\n（2）Producer发送事务消息：\nSendReceipt send(Message message, Transaction transaction) throws ClientException;\n\n（3）Producer发送异步消息：\nCompletableFuture &lt;SendReceipt&gt; sendAsync(Message message);\n\n但是，实际上在rocketmq-client-java中，我们可以发送不同类型的消息，官方文档有很清楚的记录：\n基于rocketmq-client-java 5.0 SDK，我们需要整合的消息发送方法可以具体分为以下几类：（1）Producer发送普通消息（NormalMessage）\nfinal Message message = provider.newMessageBuilder()            // Set topic for the current message.            .setTopic(topic)            // Message secondary classifier of message besides topic.            .setTag(tag)            // Key(s) of the message, another way to mark message besides message id.            .setKeys(&quot;yourMessageKey-1c151062f96e&quot;)            .setBody(body)            .build();final SendReceipt sendReceipt = producer.send(message);\n\n（2）Producer发送顺序消息（FIFOMessage）顺序消息和普通消息的不同之处就在于，需要设置消息组、保证单一生产者并且串行发送。\nfinal Message message = provider.newMessageBuilder()            // Set topic for the current message.            .setTopic(topic)            // Message secondary classifier of message besides topic.            .setTag(tag)            // Key(s) of the message, another way to mark message besides message id.            .setKeys(&quot;yourMessageKey-1ff69ada8e0e&quot;)            // Message group decides the message delivery order.            .setMessageGroup(&quot;yourMessageGroup0&quot;)            .setBody(body)            .build();final SendReceipt sendReceipt = producer.send(message);\n\n（3）Producer发送延迟消息（DelayMessage）对message设置触发时间即可，例如示例代码中我们可以对message进行如下处理：\nfinal Message message = provider.newMessageBuilder()            // Set topic for the current message.            .setTopic(topic)            // Message secondary classifier of message besides topic.            .setTag(tag)            // Key(s) of the message, another way to mark message besides message id.            .setKeys(&quot;yourMessageKey-3ee439f945d7&quot;)            // Set expected delivery timestamp of message.            .setDeliveryTimestamp(System.currentTimeMillis() + messageDelayTime.toMillis())            .setBody(body)            .build();final SendReceipt sendReceipt = producer.send(message);\n\n（4）Producer发送事务消息（TransactionMessage）\nfinal Transaction transaction = producer.beginTransaction();        // Define your message body.final Message message = provider.newMessageBuilder()            // Set topic for the current message.            .setTopic(topic)            // Message secondary classifier of message besides topic.            .setTag(tag)            // Key(s) of the message, another way to mark message besides message id.            .setKeys(&quot;yourMessageKey-565ef26f5727&quot;)            .setBody(body)            .build();final SendReceipt sendReceipt = producer.send(message, transaction);\n\n（5）Producer发送异步消息\nfinal Message message = provider.newMessageBuilder()            // Set topic for the current message.            .setTopic(topic)            // Message secondary classifier of message besides topic.            .setTag(tag)            // Key(s) of the message, another way to mark message besides message id.            .setKeys(&quot;yourMessageKey-0e094a5f9d85&quot;)            .setBody(body)            .build();        // Set individual thread pool for send callback.final CompletableFuture&lt;SendReceipt&gt; future = producer.sendAsync(message);\n\n那么接下来，我们将围绕以上的五种消息，将消息发送整合到现有的 rocketmq-spring 框架中来。我们可以首先做一个简略的基于v5 SDK整合的思维导图：\n同步消息的发送在RocketmqTemplate中我们定义syncSendGrpcMessage方法，代码如下：该方法主要是利用配置文件中的参数之前在ioc容器中管理的bean：grpcProducer，调用它的send方法达到发送同步消息的目的，其中message由spring的message转换为了client的message，作为grpcProducer.syncSendGrpcMessage方法的参数。\n/** * @param destination      formats: `topicName:tags` * @param message          &#123;@link org.springframework.messaging.Message&#125; the message to be sent. * @param messageDelayTime Time for message delay * @param messageGroup     message group name * @return SendReceipt Synchronous Task Results */public SendReceipt syncSendGrpcMessage(String destination, Message&lt;?&gt; message, Duration messageDelayTime, String messageGroup) &#123;    if (Objects.isNull(message) || Objects.isNull(message.getPayload())) &#123;        log.error(&quot;send request message failed. destination:&#123;&#125;, message is null &quot;, destination);        throw new IllegalArgumentException(&quot;`message` and `message.payload` cannot be null&quot;);    &#125;    SendReceipt sendReceipt = null;    try &#123;        org.apache.rocketmq.client.apis.message.Message rocketMsg = this.createRocketMqgRPCMessage(destination, message, messageDelayTime, messageGroup);        try &#123;            sendReceipt = grpcProducer.send(rocketMsg);            log.info(&quot;Send message successfully, messageId=&#123;&#125;&quot;, sendReceipt.getMessageId());        &#125; catch (Throwable t) &#123;            log.error(&quot;Failed to send message&quot;, t);        &#125;        grpcProducer.close();    &#125; catch (Exception e) &#123;        log.error(&quot;send request message failed. destination:&#123;&#125;, message:&#123;&#125; &quot;, destination, message);        throw new MessagingException(e.getMessage(), e);    &#125;    return sendReceipt;&#125;\n\n这个方法与remoting SDK类似，remoting SDK调用了消息转换的方法createRocketMqMessage，而我们这里并不需要一个&lt;org.apache.rocketmq.common.message.Message&gt;类型的消息实体对象，而是需要一个&lt;org.apache.rocketmq.client.apis.message.Message&gt;类型的消息实体对象，所以这里我又自定义了一个构建基于 v5-SDK 的消息构造方法：createRocketMqMessage。下面是 createRocketMqMessage 方法具体源码：\nprivate org.apache.rocketmq.client.apis.message.Message createRocketMQMessage(String destination, Message&lt;?&gt; message, Duration messageDelayTime, String messageGroup) &#123;    Message&lt;?&gt; msg = this.doConvert(message.getPayload(), message.getHeaders(), null);    return RocketMQUtil.convertToClientMessage(getMessageConverter(), charset,            destination, msg, messageDelayTime, messageGroup);&#125;\n\n这里面调用了 RocketMQUtil 中的静态方法 convertToClientMessage 用来构造一个真正的&lt;org.apache.rocketmq.client.apis.message&gt;消息实例。下面是 convertToClientMessage 方法代码：\npublic static org.apache.rocketmq.client.apis.message.Message convertToClientMessage(        MessageConverter messageConverter, String charset,        String destination, org.springframework.messaging.Message&lt;?&gt; message, Duration messageDelayTime, String messageGroup) &#123;    Object payloadObject = message.getPayload();    byte[] payloads;    try &#123;        payloads = getPayloadBytes(payloadObject, messageConverter, charset, message);    &#125; catch (Exception e) &#123;        throw new RuntimeException(&quot;convert to gRPC message failed.&quot;, e);    &#125;    return getAndWrapMessage(destination, message.getHeaders(), payloads, messageDelayTime, messageGroup);&#125;\n\n在获取了消息负载的byte数组后，我们需要封装消息实体了。下面是方法 getAndWrapMessage 源码：在这个方法里面，我们首先进行了判空操作解析了 destination 中的 topic 和 tag，取出MessageHeaders 中的属性并放到 message 的 properties 属性中，最后建造者模式调用build 方法构造了我们所需要的 message 类。\npublic static org.apache.rocketmq.client.apis.message.Message getAndWrapMessage(        String destination, MessageHeaders headers, byte[] payloads, Duration messageDelayTime, String messageGroup) &#123;    if (payloads == null || payloads.length &lt; 1) &#123;        return null;    &#125;    if (destination == null || destination.length() &lt; 1) &#123;        return null;    &#125;    String[] tempArr = destination.split(&quot;:&quot;, 2);    final ClientServiceProvider provider = ClientServiceProvider.loadService();    org.apache.rocketmq.client.apis.message.MessageBuilder messageBuilder = null;    // resolve header    if (Objects.nonNull(headers) &amp;&amp; !headers.isEmpty()) &#123;        Object keys = headers.get(RocketMQHeaders.KEYS);        if (ObjectUtils.isEmpty(keys)) &#123;            keys = headers.get(toRocketHeaderKey(RocketMQHeaders.KEYS));        &#125;        messageBuilder = provider.newMessageBuilder()                .setTopic(tempArr[0]);        if (tempArr.length &gt; 1) &#123;            messageBuilder.setTag(tempArr[1]);        &#125;        if (StringUtils.hasLength(messageGroup)) &#123;            messageBuilder.setMessageGroup(messageGroup);        &#125;        if (!ObjectUtils.isEmpty(keys)) &#123;            messageBuilder.setKeys(keys.toString());        &#125;        if (Objects.nonNull(messageDelayTime)) &#123;            messageBuilder.setDeliveryTimestamp(System.currentTimeMillis() + messageDelayTime.toMillis());        &#125;        messageBuilder.setBody(payloads);        org.apache.rocketmq.client.apis.message.MessageBuilder builder = messageBuilder;        headers.forEach((key, value) -&gt; builder.addProperty(key, String.valueOf(value)));    &#125;    return messageBuilder.build();&#125;\n\n到这里我们需要的 message 实体类就构建完成了，之后交给 rocketmq-client-java 原生的send 方法就好了。syncSend(String destination, Message&lt;?&gt; message, Duration messageDelayTime, String messageGroup) 这个方法的参数可以看出，它既支持 Normal消息的发送，同时也支持 Delay 消息(messageDelayTime参数可配置)和 FIFO 消息（messageGroup可配置）的发送。方法重载：相比于原生客户端需要自己去构建 RocketMQ Message（比如将对象序列化成 byte 数组放入 Message 对象），我们需要让 RocketMQTemplate 可以直接将对象、字符串或者 byte 数组作为参数发送出去【对象序列化操作由 RocketMQ-Spring 内置完成】我们可以定义如下重载方法：（1）Normal Message\npublic SendReceipt syncSendNormalMessage(String destination, Object payload) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, null, null);&#125;public SendReceipt syncSendNormalMessage(String destination, String payload) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, null, null);&#125;public SendReceipt syncSendNormalMessage(String destination, Message&lt;?&gt; message) &#123;    return syncSendGrpcMessage(destination, message, null, null);&#125;public SendReceipt syncSendNormalMessage(String destination, byte[] payload) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, null, null);&#125;\n\n（2）FIFO Message\npublic SendReceipt syncSendFifoMessage(String destination, Object payload, String messageGroup) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, null, messageGroup);&#125;public SendReceipt syncSendFifoMessage(String destination, String payload, String messageGroup) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, null, messageGroup);&#125;public SendReceipt syncSendFifoMessage(String destination, byte[] payload, String messageGroup) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, null, messageGroup);&#125;public SendReceipt syncSendFifoMessage(String destination, Message&lt;?&gt; message, String messageGroup) &#123;    return syncSendGrpcMessage(destination, message, null, messageGroup);&#125;\n\n（3）Delay Message\npublic SendReceipt syncSendDelayMessage(String destination, Object payload, Duration messageDelayTime) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, messageDelayTime, null);&#125;public SendReceipt syncSendDelayMessage(String destination, String payload, Duration messageDelayTime) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, messageDelayTime, null);&#125;public SendReceipt syncSendDelayMessage(String destination, byte[] payload, Duration messageDelayTime) &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return syncSendGrpcMessage(destination, message, messageDelayTime, null);&#125;public SendReceipt syncSendDelayMessage(String destination, Message&lt;?&gt; message, Duration messageDelayTime) &#123;    return syncSendGrpcMessage(destination, message, messageDelayTime, null);&#125;\n\n他们底层都调用了syncSendGrpcMessage方法。\n异步消息的发送我们定义了如下一个异步消息的发送方法 asyncSend。类似的，他的核心方法调用了 rocketmq-client-java 原生的sendAsync异步发送消息方法：future &#x3D; grpcProducer.sendAsync(rocketMsg);\npublic CompletableFuture&lt;SendReceipt&gt; asyncSend(String destination, Message&lt;?&gt; message, Duration messageDelayTime, String messageGroup, CompletableFuture&lt;SendReceipt&gt; future) &#123;    if (Objects.isNull(message) || Objects.isNull(message.getPayload())) &#123;        log.error(&quot;send request message failed. destination:&#123;&#125;, message is null &quot;, destination);        throw new IllegalArgumentException(&quot;`message` and `message.payload` cannot be null&quot;);    &#125;    Producer grpcProducer = this.getProducer();    try &#123;        org.apache.rocketmq.client.apis.message.Message rocketMsg = this.createRocketMQMessage(destination, message, messageDelayTime, messageGroup);        future = grpcProducer.sendAsync(rocketMsg);    &#125; catch (Exception e) &#123;        log.error(&quot;send request message failed. destination:&#123;&#125;, message:&#123;&#125; &quot;, destination, message);        throw new MessagingException(e.getMessage(), e);    &#125;    return future;&#125;\n\n\n事务消息的发送与普通消息发送不同的是，我们需要在事务消息中调用grpcProducer.beginTransaction()开启事务，并且还要提交事务transaction.commit()。\npublic Pair&lt;SendReceipt, Transaction&gt; sendMessageInTransaction(String destination, Object payload) throws ClientException &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return sendTransactionMessage(destination, message);&#125;public Pair&lt;SendReceipt, Transaction&gt; sendMessageInTransaction(String destination, String payload) throws ClientException &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return sendTransactionMessage(destination, message);&#125;public Pair&lt;SendReceipt, Transaction&gt; sendMessageInTransaction(String destination, byte[] payload) throws ClientException &#123;    Message&lt;?&gt; message = MessageBuilder.withPayload(payload).build();    return sendTransactionMessage(destination, message);&#125;/** * @param destination formats: `topicName:tags` * @param message     &#123;@link Message&#125; the message to be sent. * @return CompletableFuture&lt;SendReceipt&gt; Asynchronous Task Results */public Pair&lt;SendReceipt, Transaction&gt; sendTransactionMessage(String destination, Message&lt;?&gt; message) &#123;    if (Objects.isNull(message) || Objects.isNull(message.getPayload())) &#123;        log.error(&quot;send request message failed. destination:&#123;&#125;, message is null &quot;, destination);        throw new IllegalArgumentException(&quot;`message` and `message.payload` cannot be null&quot;);    &#125;    final SendReceipt sendReceipt;    Producer grpcProducer = this.getProducer();    org.apache.rocketmq.client.apis.message.Message rocketMsg = this.createRocketMQMessage(destination, message, null, null);    final Transaction transaction;    try &#123;        transaction = grpcProducer.beginTransaction();        sendReceipt = grpcProducer.send(rocketMsg, transaction);        log.info(&quot;Send transaction message successfully, messageId=&#123;&#125;&quot;, sendReceipt.getMessageId());    &#125; catch (ClientException e) &#123;        log.error(&quot;send request message failed. destination:&#123;&#125;, message:&#123;&#125; &quot;, destination, message);        throw new RuntimeException(e);    &#125;    return new Pair&lt;&gt;(sendReceipt, transaction);&#125;\n\n\n封装消息接收方法\nPushConsumer消息接收因为之前在RocketmqProperties中已经将bean：pushConsumerBuilder 注入了ioc容器中，现在只需要让用户定义消息监听处理方式，然后在初始化时将 pushConsumerBuilder所需要的参数传入就可以了。\n private void initRocketMQPushConsumer() &#123;    if (rocketMQMessageListener == null) &#123;        throw new IllegalArgumentException(&quot;Property &#x27;rocketMQMessageListener&#x27; is required&quot;);    &#125;    Assert.notNull(consumerGroup, &quot;Property &#x27;consumerGroup&#x27; is required&quot;);    Assert.notNull(topic, &quot;Property &#x27;topic&#x27; is required&quot;);    Assert.notNull(tag, &quot;Property &#x27;tag&#x27; is required&quot;);    FilterExpression filterExpression = null;    final ClientServiceProvider provider = ClientServiceProvider.loadService();    if (StringUtils.hasLength(this.getTag())) &#123;        filterExpression = RocketMQUtil.createFilterExpression(this.getTag(),this.getType());    &#125;    ClientConfiguration clientConfiguration = RocketMQUtil.createClientConfiguration(this.getAccessKey(), this.getSecretKey(), this.getEndpoints(), this.getRequestTimeout());    PushConsumerBuilder pushConsumerBuilder = provider.newPushConsumerBuilder()            .setClientConfiguration(clientConfiguration);    // Set the consumer group name.    if (StringUtils.hasLength(this.getConsumerGroup())) &#123;        pushConsumerBuilder.setConsumerGroup(this.getConsumerGroup());    &#125;    // Set the subscription for the consumer.    if (StringUtils.hasLength(this.getTopic()) &amp;&amp; Objects.nonNull(filterExpression)) &#123;        pushConsumerBuilder.setSubscriptionExpressions(Collections.singletonMap(this.getTopic(), filterExpression));    &#125;    pushConsumerBuilder            .setConsumptionThreadCount(this.getConsumptionThreadCount())            .setMaxCacheMessageSizeInBytes(this.getMaxCacheMessageSizeInBytes())            .setMaxCacheMessageCount(this.getMaxCachedMessageCount())            .setMessageListener(rocketMQListener);    this.setPushConsumerBuilder(pushConsumerBuilder);&#125;\n\n\nSimpleConsumer消息接收\n同步接收消息我们定义了一个 receive 方法作为 SimpleConsumer 的消息接收方法，并且传入参数maxMessageNum指定了每次长轮询的最大消息数，invisibleDuration 指定了设置消息接收后的不可见持续时间。\npublic List&lt;MessageView&gt; receive(int maxMessageNum, Duration invisibleDuration) throws ClientException &#123;    SimpleConsumer simpleConsumer = this.getSimpleConsumer();    return simpleConsumer.receive(maxMessageNum, invisibleDuration);&#125;\n\n进行消息确认：\npublic void ack(MessageView message) throws ClientException &#123;    SimpleConsumer simpleConsumer = this.getSimpleConsumer();    simpleConsumer.ack(message);&#125;\n\n\n异步接收消息receiveAsync方法返回一个CompletableFuture类型的异步返回结果，对于这个结果的处理，用户可以在调用rocketmqTemplate.receiveAsync之后自行处理。\npublic CompletableFuture&lt;List&lt;MessageView&gt;&gt; receiveAsync(int maxMessageNum, Duration invisibleDuration) throws ClientException, IOException &#123;    SimpleConsumer simpleConsumer = this.getSimpleConsumer();    CompletableFuture&lt;List&lt;MessageView&gt;&gt; listCompletableFuture = simpleConsumer.receiveAsync(maxMessageNum, invisibleDuration);    simpleConsumer.close();    return listCompletableFuture;&#125;\n\n进行消息确认：\npublic CompletableFuture&lt;Void&gt; ackAsync(MessageView messageView) &#123;    SimpleConsumer simpleConsumer = this.getSimpleConsumer();    return simpleConsumer.ackAsync(messageView);&#125;","tags":["开源之夏"]},{"title":"Git-Flow 团队代码分支管理模型初体验","url":"/2023/10/19/Git-Flow%20%E5%9B%A2%E9%98%9F%E4%BB%A3%E7%A0%81%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9E%8B%E5%88%9D%E4%BD%93%E9%AA%8C/","content":"前言\n我们知道，Git最初是由Linux开发者Linus用了仅仅两周时间纯C语言编写而成。在日常工作中git是不可或缺的工具。除了需要熟练掌握Git命令，我们还需要了解究竟如何将 Git Flow 这一款适用于代码分支管理到模型应用到团队中，这也是本文的目的。\n大约在13年前（2010年），Vincent Driessen 提出了赫赫有名的 Git 分支管理模型。开发者如果要开发一个新的功能（feature），需要从develop分支checkout一个新的feature分支，然后做自己的修改。修改完成后，还需要merge回develop分支。接下来针对Git 分支管理模型，我们在原文的基础上，进行一些讨论与分析。\n\n除了像git这样的分布式版本控制系统，n年前还有过 svn、cvs 等等一系列版本控制系统，它们的区别在于：前者是分布式，后者是集中式。在传统的 CVS 或 Subversion 中，合并分支是一件让人担惊受怕的事情。集中式的版本控制系统每次在写代码时都需要从服务器中拉取一份下来，并且如果服务器丢失了，那么所有的就都丢失了。分布式与集中式的区别在于，每个人的电脑都是服务器，你可以自由在本地回滚，提交，当你想把自己的代码提交到主仓库时，只需要合并推送到主仓库就可以了。集中式它们都有一个主版本号，所有的版本迭代都以这个版本号为主；而分布式因为每个客户端都是服务器，git没有固定的版本号，但是有一个由哈希算法算出的id，用来回滚用的。 同时后者也有一个master仓库，这个仓库是一切分支仓库的主仓库，我们可以推送提交到master并合并到主仓库上，主仓库的版本号会迭代一次，我们客户端上的git版本号无论迭代多少次，都跟master无关，只有合并时，master才会迭代一次。 \n分支管理模型概览我们首先用四段话来概括Vincent Driessen提出的模型的核心内容：\n\n对于feature分支： 我们首先需要从 develop 分支 checkout 一个新的feature分支，然后做自己的开发&#x2F;修改。操作完成后，再 merge 回 develop 分支。\n对于develop分支： 开发人员将 feature&#x2F;release 等等辅助分支合并回 develop 分支前，需要成功跑完CI流水线，然后进行合并。develop 分支集成其他分支所做的一切修改。\n对于release分支： 我们需要切一个 release 分支，创建一条新的CD流水线。release 成功结束后，一般会 merge 回 master 分支，并在master分支打下版本Tag。\n对于hotfix分支：如果 release 之后发现有bug，需要紧急处理，这时我们就需要热修复，从 master 分支的某个 tag 切出来，修复好问题后再 merge 回 master，打下新的版本 tag，而且还要同步 merge 回 develop。\n\n模型图如下：\n主线分支Git 中央存储库中包含两个重要的分支，一个是master，另一个是develop。它们在项目的生命周期中都一直存在。这两个分支有如下特性：\n\norigin&#x2F;master分支反映的一直都是发布就绪的状态。master分支上的代码也是生产服务的代码。原则上，master分支的代码都是可发布的，所以我们对merge到master的代码有严格的要求。\norigin&#x2F;develop分支反映当前项目的修改状态。 该分支集成其他分支所做的一切修改。甚至可以运行一个自动化脚本，每天晚上将各个分支的修改merge到develop分支。当develop分支中的代码趋于稳定，准备发新版的时候，应该将其merger到master分支，并标记本次发布的版本号。\n\n\n辅助分支如 master 和 develop 旁边的其他分支，它们的生命周期有限，最终会从代码库中被移除。 而我们使用这些分支，主要来帮助各个团队之间并行开发，或者是为新版本发布做准备，亦或修复当前生产环境的bug。我们使用的分支有以下几种：Feature branches、Release branches 与 Hotfix branches。 各个分支根据不同的目的被创建，对它们的操作也遵循严格的规则。比如分支如何创建、开发完成之后merge到的对象等。另外，这些分支其实都是普通的git分支。只是根据我们使用的目的策略给他们赋予了不同的功能。接下来我们来详细介绍这三种辅助分支。\nFeature 分支Feature 分支主要用来开新功能。 一般来说，只要功能还没有开发完善，它就应该一直存在。但最终应该被 merge 回 develop 分支或者丢弃。Feature 分支遵循以下规则：\n\n从 develop 分支上创建 feature 分支\nfeature 分支最终 merge 回 develop 分支\n分支的命名规则：除了master、develop、release- 、or hotfix- 的任何名字，一般可以用feature-为前缀命名。\n\nFeature 分支通常只存在于开发人员的版本库中，而不应该存在于 origin 仓库中。 但考虑到团队成员协作开发的情况，彼此之间需要定期 merge 对方的代码，这是就需要借助 develop 分支来实现了。\n创建feature分支git checkout -b feature-1020 develop\n合并feature分支git checkout develop            #切换到develop分支git merge --no-off feature-1020 #合并feature-1020的代码到本地master分支git branch -d feature-1020      #删除本地feature分支git push origin develop         #推送到远程develop仓库\nRelease 分支Release 分支主要用来为代码发布做准备。 在合并代码之前，它允许做小的 bug 修改、为版本发布做准备工作（指定版本号、建数据表等）。通过在 Release 分支上做这些操作，可以保证 develop 分支是干净的，不影响当前新功能的开发。Release 分支遵循下面的规则：\n\n从 develop上创建release分支\nrelease 必须 merge 回 develop 和 master\n分支需要以 release-* 来命令当完成本次发版计划的所有功能，并且新功能也到达了预期的状态，那么就是时候创建 release 分支了。这个时候，本次计划发版的所有功能分支，都应该被 merge 回develop 分支。其他的不在本次版本计划中，需要等到下次创建 release 分支的时候再进行 merge。在创建 release 分支的时候，即已经确定了本次发版的版本号。\n\n创建release分支release 分支从 develop 分支中创建。举例说明：当前生产环境的版本是1.1.5，接下来我们计划要发新版。当开发状态基本满足发版的需求时，我们决定本次的版本号为1.2。因为我们创建 release 分支，并给分支指定一个版本号：\ngit checkout -b release-1.2 develop             #新建并签出release-1.2分支./bump-version.sh 1.2                           #执行虚构的shell脚本，修改部分文件，以反映当前新的版本号git commit -a -m &quot;Bumped version number to 1.2&quot; #提交当前release-1.2分支版本修改的变更\n这里 bump-version.sh 是虚构的一个shell脚本，用来修改部分文件，以反映当前新的版本号（这当然也可以手工来修改这些文件）。直到新版上线之前，release分支都始终应该存在。在这段期间里，还可以继续修改bug（当然是在relase分支上修改，而不是develop）。这个时候，给release分支增加新的功能是被明确禁止的，新的功能必须merge到develop分支，等到下一次版本发布。\n完成release分支当 release 分支的状态已经完全可以发版时，我们还需要执行以下操作：\n\nrelease 分支需要merge到master分支上。 因为 master 分支上的提交才真正表示一个新的发布版本。\n给 master 分支上的这次提交打tag，方便未来参考该历史版本。\n代码还需要 merge 回 develop 分支， 这样可以保证未来的版本也包含了 release 中的修改。\n\n合并到master：\ngit checkout master             //签出master分支git merge --no-ff release-1.2   //合并release-1.2分支提交的代码git tag -a 1.2                  //为本次提交打上tag\n\n为了保存release中所作的修改，我们还需要将release分支merge到develop：\ngit checkout develop            //签出develop分支git merge --no-ff release-1.2   //合并release-1.2分支变更到develop\n\n这的merge操作可能会导致冲突（因为我们在release中做了修改）。如果真是这样，修复它，然后重新提交。现在所有工作已经完成，release分支已经不再被需要了。\ngit branch -d release-1.2       //删除release-1.2分支\nHotfix分支Hotfix分支主要用来修复当前线上出现的Bug。 和release分支的相同点在于，也是为新的发布版本做准备。但对于该版本，前期却是没有任何计划的。当生产环境的版本出现不期望的状况并需要立即修复时，Hotfix应运而生。当生产环境出现严重的bug，必须立即去解决。hotfix是从当前生产环境的master分支上的tag标签生成的。hotfix分支遵循下面的规则：\n\n从master分支上创建\n最终merge到master和develop分支\n分支命名规则为：hotfix-*Hotfix分支的核心在于：当前开发团队仍然可以继续开发，由另外一个人来快速修复bug。\n\n创建hotfix分支Hotfix从master分支上创建。举个例子，当前生产服务的运行版本是1.2。比较麻烦的是，服务上出现了一个bug，我们需要立即修复。 我们就可以创建一个hotfix分支，着手修改这个bug：\ngit checkout -b hotfix-1.2.1 master                #创建并切换到hotfix-1.2.1分支./bump-version.sh 1.2.1git commit -a -m &#x27;Bumped version number to 1.2.1&#x27;  #提交当前分支版本修改的变更\n\n创建分支之后，不要忘记去做版本修改。然后我们就可以在hotfix分支上一步一步修复这个bug了。\ngit commit -m &#x27;Fixed server production problem&#x27;    #提交修改bug后的分支变更\nhotfix分支完成修复当修复完成后，代码需要 merge 到 master 分支和 develop 分支，这样后续的版本中也会包含该修改。这跟 release 分支的操作是完全相同的。\n\n首先，切换到 master 分支，merge 做的修改，然后打标签。\ngit checkout master              #切换到master分支git merge --no-ff hotfix-1.2.1   #合并分支git tag -a 1.2.1                 #打标签\n\n接下来，将修改merge到develop分支：\ngit checkout develop             #切换到develop分支git merge --no-ff hotfix-1.2.1   #合并当前修改到develop分支\n注意： 对于这个规则，存在一个例外情况：当前有一个待发布的 release 分支已经存在了。如果可以延迟到伴随这个 release 发版，才修复这个问题，hotfix 分支就需要 merge 到 release 分支上，而不是develop。 因为当release分支完成之后，最终修改还是会 merge 到 develop 分支上（如果当前的服务非常需要这个修复，不能等到下次发版，你就还需要merge到develop分支上了，也就是始终要保证develop包含master分支）。\n\n最终从代码库中移除分支：\ngit branch -d hotfix-1.2.1\n\n","tags":["Git"]},{"title":"GSoC-2023 RocketMQ 社区的申请全过程","url":"/2023/10/14/%E5%9B%9E%E9%A1%BEGSoC-2023RocketMQ%E7%A4%BE%E5%8C%BA%E7%9A%84%E4%B8%80%E6%AC%A1%E7%94%B3%E8%AF%B7/","content":"\nGSoC-2023：官网链接  组织列表  时间列表GSoC-2023：Integrate RocketMQ 5.0 client with Spring 选题链接本次选题相关 ISSUE：Rocketmq-Clients Issue  Rocketmq-Spring Issue\n\n前言在 GSoC-2023，我申请的课题是 RocketMQ-5.0-gRPC 客户端集成 Spring 这一课题。不过遗憾的是，最后课题并未中选，但是本课题的开发任务还是由我来完成，到目前为止，代码也已经合并到官方仓库 [PR 链接]。题目虽未能入选，但是仍由我参与开发任务，这与 GSoC 的活动机制有关，在接下来的内容中我会进行详细说明。\n契机其实在年初的时候还不知道有这样一个活动，那时候只知道国内的 开源软件供应链点亮计划（OSPP） 和 阿里巴巴编程之夏（ASoC），后面在一篇公众号推文中，偶然了解到 GSoC。这几个开源活动的申请时间线也比较有趣，GSoC在申请结束并公布中选情况后，差不多就到了 OSPP&#x2F;ASoC 的申请开发时间，OSPP申请截止后，又到了 GitLink编程夏令营（GLCC） 的申请时间，所以如果GSoC没用中选也没关系，可以在后面几个活动中继续尝试。而且某些“落选”的题目，也很可能成为接下来一个活动的题目。\n准备\n尽快与导师进行联系。 当选题公布出来的时候，官网里往往会留下导师的邮箱。如果你熟悉这个社区，甚至可以提前写出你关于选题的一些思考和想法，然后与导师进行邮箱交流，这时导师可能会继续给你提出要求，因此你需要继续去深入了解相关部分的代码。如果你能添加上导师的 WeChat，交流起来显然会更方便。不过这不意味着你一定能入选，但是这对你进行下一步的思考以及写提案会有很大的帮助。\n选题与竞争。 既然是开源活动，参与者肯定不少，因此打算做这个选题的人也不止一个。所以往往你还需要去 Github 里找到对应 issue，留言表示自己对该选题的兴趣和意愿，希望进一步沟通。如果你想知道目前这个 Task 的潜在参与者有多少，可以根据社区活跃度与留言人数进行粗略的判断。\n进行有思考的对话并大胆提问。 与导师交流，不管是提问还是回复消息，都需要仔细思考后再行动。如果导师向你进一步提问，你可以不用急着立刻回复他，但是一定要经过深思熟虑后回答。但是这也不意味着你跟导师交流就要怯懦，在某些话题下，例如你好奇目前选题的竞争人数，或者完全不理解题目要求是什么，你可以大胆提问，相信导师会为你释疑。\n不建议同时准备太多选题。 这样会忙于奔波，最后可能一个社区也入选不了。所以你在根据自我能力与项目难度进行综合评估后，选择一个你觉得最合适的选题，把精力集中在一个选题上，这样能够大大提高入选概率。\n\n为什么谷歌编程之夏能吸引全球众多开发者官网是这样介绍GSoC的：\n\nGoogle Summer of Code is a global, online program focused on bringing new contributors into open source software development. GSoC Contributors work with an open source organization on a 12+ week programming project under the guidance of mentors.\n\n用中文翻译即是，学生会用大概一个暑假的时间在导师的指导下为开源社区写代码，Google 为你的工作支付报酬。而 GSoC 的报酬很让人心动，例如一个 Medium Size Projects 可以获得1800 刀，而一个 Large Size Projects 可以获得3600 刀，具体表格可以参照 2023 年贡献者奖金。所以这也导致了，他的筛选条件十分严格，中选难度很大。\n\n另外，自2005年以来，谷歌编程之夏计划已经连接了来自112个国家的19000名新的开源贡献者和来自133个国家的18000名导师。Google Summer of Code已经为800个开源组织生成了超过4300万行代码。\n以学生的视角出发，体悟这次开源活动\n其实于我而言，很多时候并不知道自己是基于怎样的考量才开始做一件事。自打挣扎着从高考的棺椁里爬出来，才终于见到一点点粘稠的阳光。想想自己一路走来，在负而前驱的道路上，活得虚伪又狼狈。\n处心积虑想把每一件事都顾虑周全，总会有些左支右绌；然亦步亦趋地跟在人群后面，又总觉得少了些特立独行的影子。但人总是裹挟着平凡在成长，所以我不敢抬头，亦不敢低头，唯有平视才能与自己和解。\n\n大概是今年三月初的时候，偶然得知了 GSoC 这样一个开源活动。但最担心的一个问题是，跟导师和社区都不太熟，给导师发邮件联系不知道他们会不会回复。后面还是鼓起勇气写下了自己对选题不太成熟的理解。迈出第一步，才发现的确是多虑了，社区导师都比较好说话，只要你有想法和思考，他们都愿意和你交流。\n为了让社区导师更好地了解我的情况，可以附上自己的简历，不用像求职简历那样详尽，但是一定要有自己的基本信息（例如姓名和学校），以及为什么能够胜任这个选题的原因（比如是否具有相关能力、技术栈、经历）。另外，基于当时我自己对 rocketmq 浅显的了解，我又写了篇对课题的思考与实现思路，作为附件和简历一起发给了导师。但这些都不是最重要的事情，因为最后提交到官网的提案才是你中选的关键。\n在了解大致开发任务之后，可以到 github 上留言，这意味着让社区导师和潜在参与者可以知道你有当前选题的意向。在这里我们可以清楚地看到有多少人打算做这个题目，并且了解他们的background。\n一个比较有意思的点是，我课题的 Issue 下面很是热闹，大多数希望参加是国内的同学，但仍有不少国外的朋友。这也是第一次切身感受到 GSoC 的国际影响力。\n另外，在GSoC官网里面还一个比较抽象的统计，详情如下图所示，GSoC 在全世界录取人数最多的 top12 所学校均来自印度。\n接下来还要完成一件重要的事情，就是熟悉社区现有版本代码的使用。在跑通社区提供的用例之后，才来到编码的核心环节。\n总体来说，这次开发任务也并不轻松，因为要同时参考 rocketmq-clients 与 rocketmq-spring 两个仓库的代码。所以在后面将近一个多月的时间里，看着源码反复琢磨着设计思路，之后在完成编码后进行测试用例的覆盖。\n在完成这些事情后，距离提案提交截至还有一两个星期左右，我把代码上传到仓库，然后继续完善提案，并准备一份English-Version提案，所以需要做一个 Translation，把最后的 English-Version 提案最后提交到官网。\n提案的内容详尽程度是越详细越好，不用担心太长会显得臃肿，如果能贴上代码是更好的。\n在提交提案时一定要注意，尽量提前几天提交，不要赶DDL。在截止日期之前，提案是可以被反复修改的。\n\n之后，便是一个月的漫长等待时间。因为国际时间的缘故，中国学生收到邮件的时间大概在半夜三点左右。那天一直熬到凌晨三点，并没有消息推送到邮箱。后面实在熬不住睡着了，大概在凌晨五点的时候我突然醒来，收到了GSoC的落选信。\n虽然题目没有中选，但由于我提案的 Ranking 排第一，所以还是有机会继续完成剩下的工作。\n不过谈到 GSoC 中选率也是比较感人的，这里以 Apache RocketMQ 和 Apache Dubbo 两个社区为例：\n上图是 Apache Rocketmq 社区和 Apache Dubbo 社区放置到 GSoC 上的选题，但是今年这两个社区中选的人数都只有2人。\n谷歌官方的评选逻辑是，首先导师对每个题目下的提案进行排序，谷歌会给每个组织&#x2F;社区一个中选名额，题目还会经过谷歌官方的筛选，如果你的题目被谷歌选中了，并且你的排名还在第一，这才意味着中选。但即使最后题目没能被 GSoC 官方选中，如果你的提案被导师认可，仍然可以去完成这个工作，不过就没有 GSOC 的奖金可以拿了。\n今年的 GSoC 之旅就以这样的结局收尾了。第一次尝试去参加全球性的开源活动，也算是 coding 路上一件饶有兴趣的事情。\n月光如水照缁衣，新的生活还要继续。\n","tags":["开源之夏"]},{"title":"JRaft-jepsen 线性一致性测试","url":"/2023/09/11/JRaft-jepsen-%E7%BA%BF%E6%80%A7%E4%B8%80%E8%87%B4%E6%80%A7%E6%B5%8B%E8%AF%95/","content":"\n本文记录了 Jepsen 框架对 SOFA-JRaft 进行一致性检验的环境搭建和部署流程。如今网上并没有 JRaft-Jepsen 一致性检验的环境搭建教程，JRaft 官方仓库也没有给出完整的环境搭建教程。本文所有的部署流程操作是通过试错得来。试错过程遇到了不少坑，于是总结此文，希望以后的 Jraft-Jepsen 检验能有值得参考的文章。\n\nJepsen前置资料参考：Jepsen中文官方文档   Jepsen作者博客Cloujre前置资料：Clojure入门文章-英文版   Clojure中文文档\n线性一致性概述概念如果说你对线性一致性（Linearizability）概念不太熟，那一定知道强一致性（strong consistency），或者说原子一致性（atomic consistency），也可以理解为的 CAP 理论中的 C。\nRaft线性一致性的实现线性一致性写所有的 read&#x2F;write 都会来到 Leader，write 会有 Log 被序列化，依次顺序往后 commit，并 apply 然后在返回，那么一旦一个 write 被 committed，那么其前面的 write 的 Log 一定就被 committed 了。 所有的 write 都是有严格的顺序的，一旦被 committed 就可见了，所以 Raft 是线性一致性写。\n线性一致性读线性一致性读有很多种方法可以去实现，例如以下介绍了四种实现线性一致性读的办法：\n\nRaft Log read：每个 read 都有一个对应的 Log，和 write 一样，将非事务请求以事务请求的逻辑去进行处理。在 Read Log 被 Apply 的时候读，那么此时这个 read Log 之前的 write Log 也一定被 applied 了，那么读到的数据一定是最新的。\nReadIndex：我们知道 Raft log read，会有 Raft read log 的复制和提交的开销，所以出现了 ReadIndex。当 read 请求发送给 Leader 的时候：（1）首先需要确认 read 必须返回最新 committed 的结果。但是一个节点刚当选 Leader 的时候并不知道最新的 committed index，这个时候需要提交一个 Noop Log Entry 来提交之前的 Log Entry，然后开始 Read；（2）确认当前的 Leader 是不是还是 Leader。可能由于网络分区，这个 Leader 已经被孤立了，所以 Leader 在返回 read 之前，先和 Replica-Group 的其他成员发送 heartbeat 确定自己 Leader 的身份；通过上述两条才可以保证读到的是最新刚被 committed 的数据。\nLease read：主要是通过 lease 机制维护 Leader 的状态，来减少了 ReadIndex 每次 read 发送 heartheat 的开销。\nFollower read：先去 Leader 查询最新的 committed index，然后拿着 committed Index 去 Follower read，从而保证能从 Follower 中读到最新的数据，当前 Etcd 和 SOFA-Jraft 就实现了 Follower read。\n\n关于SOFA-JRaft实现线性一致性读可参考文章：SOFAJRaft 线性一致读实现剖析\nJepsen 概述Jepsen 是由 Kyle Kingsbury 采用函数式编程语言 Clojure 编写的验证分布式系统一致性的测试框架，作者使用它对许多著名的分布式系统（etcd, cockroachdb…）进行了“攻击”（一致性验证），并且帮助其中的部分系统找到了 bug。网上已有文章对其原理进行过简述，此处贴上链接即可：当 TiDB 遇上 Jepsen\nJraft-Jepsen 部署验证一致性\n下面的内容是作者自己踩坑总结出来的部署流程，介绍了如何手动部署一套Jepsen框架对JRaft代码进行一致性验证。\n\n打开gitpod&#x2F;linux运行ubuntu容器，其中1个control节点，5个jraft-test节点。\ndocker run -itd --name ubuntu-1 --hostname control --privileged=true ubuntudocker run -itd --name ubuntu-2 --hostname jraft1 --privileged=true ubuntudocker run -itd --name ubuntu-3 --hostname jraft2 --privileged=true ubuntudocker run -itd --name ubuntu-4 --hostname jraft3 --privileged=true ubuntudocker run -itd --name ubuntu-5 --hostname jraft4 --privileged=true ubuntudocker run -itd --name ubuntu-6 --hostname jraft5 --privileged=true ubuntu\n\n查找所有容器的ip\ndocker inspect --format=&#x27;&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27; $(docker ps -aq)\n\n进入容器\ndocker exec -it ubuntu-1 bash\n\n修改hosts文件，添加ip与域名的对应关系\nvim /etc/hosts\n\n此处根据查询出的容器ip对应填写即可\n127.0.0.1       localhost::1     localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.2      control172.17.0.3      jraft1172.17.0.4      jraft2172.17.0.5      jraft3172.17.0.6      jraft4172.17.0.7      jraft5\n\n设置Docker-SSH免密登录安装SSH服务\napt-get update apt-get install openssh-server //安装ssh服务\n\n开启SSH服务\n/etc/init.d/ssh startps -e | grep ssh  //检查是否开启ssh\n\njraft-test节点在Test-Node的docker容器内，编辑文件&#x2F;etc&#x2F;ssh&#x2F;sshd_config，添加一行PermitRootLogin yes表示ssh允许root登录。\necho &quot;PermitRootLogin yes&quot; &gt;&gt; /etc/ssh/sshd_config# 或者 vim /etc/ssh/sshd_config 并手敲一行PermitRootLogin yes\n\n随后一定要重启ssh服务\nservice ssh restart\n\n设置root密码\npasswd root\n\ncontrol节点ssh-keygen //生成公钥私钥ssh-copy-id -i /root/.ssh/id_rsa.pub root@jraft1ssh-copy-id -i /root/.ssh/id_rsa.pub root@jraft2ssh-copy-id -i /root/.ssh/id_rsa.pub root@jraft3ssh-copy-id -i /root/.ssh/id_rsa.pub root@jraft4ssh-copy-id -i /root/.ssh/id_rsa.pub root@jraft5\n\n私钥文件格式问题：您需要确保您的SSH私钥文件格式正确，并且Jepsen测试工具可以正确识别它。通常，SSH私钥文件格式为OpenSSH格式。您可以尝试使用以下命令将私钥文件转换为OpenSSH格式：\nssh-keygen -p -f /root/.ssh/id_rsa -m pem -t rsa\n\nUbuntu工具安装control节点安装：\napt-get update apt-get install leiningenapt-get install wgetapt-get install gitapt-get install vimapt-get install sudoapt-get install iptables\n\ntest节点安装：\napt-get update apt-get install leiningenapt-get install wgetapt-get install vimapt-get install sudoapt-get install iptables\n\nubuntu容器安装jdk-8：进入目录：\nmkdir /usr/local/java &amp;&amp; cd /usr/local/java\n\nwget下载jdk8：\nwget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-x64.tar.gz&quot;\n\n解压：\ntar -zxvf jdk-8u141-linux-x64.tar.gz -C /usr/local/java\n\n编辑配置文件：此处需要注意，有可能在安装其他安装包时会自动安装jdk11，此处需要修改两个配置文件才能生效，并且修改为jdk8.\nvim ~/.bashrc\n\nexport JAVA_HOME=/usr/local/java/jdk1.8.0_141export PATH=$JAVA_HOME/bin:$PATH\n\nvim /etc/profile\n\nexport JAVA_HOME=/usr/local/java/jdk1.8.0_141export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH\n\n执行命令使配置文件生效：\nsource /etc/profile\n\n安装clojure-control此操作在control节点完成：复制链接中的shell脚本：https://raw.githubusercontent.com/killme2008/clojure-control/master/bin/control\ncd ~/binvim control\n\n将shell脚本粘贴到control中\nchmod 777 control\n\n设置control系统变量\nexport CONTROL_ROOT=1\n\nexport PATH=$PATH:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/bin\n\n下载jraft测试代码克隆远程仓库代码：\ngit clone jraft仓库（自测仓库/官方仓库）\n\n安装jar到本地仓库：\nmvn clean install -DskipTests=true\n\n部署atomic-server此操作在control节点执行：\ncontrol run jraft buildcontrol run jraft deploy\n\n开启测试bash开启测试configuration-test\nbash run_test.sh --testfn configuration-test --username root --password 123 --ssh-private-key /root/.ssh/id_rsa\n\nbridge-test\nbash run_test.sh --testfn bridge-test --username root --password 123 --ssh-private-key /root/.ssh/id_rsa\n\npause-test\nbash run_test.sh --testfn pause-test --username root --password 123 --ssh-private-key /root/.ssh/id_rsa\n\ncrash-test\nbash run_test.sh --testfn crash-test --username root --password 123 --ssh-private-key /root/.ssh/id_rsa\n\npartition-test\nbash run_test.sh --testfn partition-test --username root --password 123 --ssh-private-key /root/.ssh/id_rsa\n\npartition-majority-test\nbash run_test.sh --testfn partition-majority-test --username root --password 123 --ssh-private-key /root/.ssh/id_rsa\n\n测试方法\nconfiguration-testbridge-testpause-testcrash-testpartition-testpartition-majority-test\n\n潜在问题及解决方案如果出现报错：\nCould not find artifact apache-codec:commons-codec:jar:1.2 in central (https://repo1.maven.org/maven2/)Could not find artifact apache-codec:commons-codec:jar:1.2 in clojars (https://repo.clojars.org/)This could be due to a typo in :dependencies, file system permissions, or network issues.If you are behind a proxy, try setting the &#x27;http_proxy&#x27; environment variable.Uberjar aborting because jar failed: Could not resolve dependencies\n\n解决办法：\ncd ~/.m2/repository/apache-codec/commons-codec/1.2\n\n可以看到里面是空的，此时拉取远程仓库jar包即可\nwget https://repo1.maven.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.pomwget https://repo1.maven.org/maven2/commons-codec/commons-codec/1.2/commons-codec-1.2.jar","tags":["SOFA-JRaft"]}]